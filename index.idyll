[meta title:"Wie Maschinen Kommentare verstehen ‚Äì Kommentare.vis.one" description:"Maschinelles Lernen wird als L√∂sung verkauft, um Hass aus dem Internet zu filtern. Diese Webseite erkl√§rt wie 'die Maschinen' die Bedeutung von W√∂rtern erlernen." url:"https://kommentare.vis.one/" twitterHandle:"@fil_ter" shareImageUrl:"https://kommentare.vis.one/static/images/preview.png" /]


[FilterHeader
  subtitle:"Machine Learning wird als L√∂sung verkauft, um Hass aus dem Internet zu filtern. Diese Webseite erkl√§rt, wie Computer die Bedeutungen von W√∂rtern erlernen."
  fullWidth:true
  author:"Johannes Filter"
  authorLink:"https://johannesfilter.com"
  date:"15. M√§rz 2020"
  background:"#222222"
  color:"#ffffff"
/]

[MovingTexts /]

// https://github.com/FormidableLabs/victory/blob/master/packages/victory-core/src/victory-theme/grayscale.js

[derived name:'scatter-theme' value:`{
  axis: {
    style: {
      axis: {
        fill: 'transparent',
        stroke: 'transparent'
      },
      grid: {
        stroke: 'transparent',
      },
      tickLabels: {
        stroke: 'transparent',
        fill: 'transparent'
      }
    }
  },
  scatter: {
    style: {
      data: {
        fill: "black",
        cursor: 'pointer',
        opacity: 0.8
      },
      labels: {
        fontFamily: 'lato',
        fontSize: () => Math.max(window.screen.width, window.innerWidth) < 768 ? 20 :  8,
        letterSpacing: 'normal',
        padding: 3,
        fill: 'charcoal',
        stroke: "transparent"
      }
    }
  }
}` /]

In den Kommentarspalten tobt der Hass. Um diesen einzud√§mmen, pr√ºfen Zeitungsredaktionen manuell die Kommentare. Das ist personal- und zeitaufwendig. Und bei manchen Themen, ist es f√ºr die Medienh√§user kaum noch m√∂glich, die Vielzahl an Kommentaren zu moderieren. Da wird dann die Kommentarfunktion mitunter einfach ganz abgeschaltet, um sich vor einer Flut an Hass-Kommentaren zu sch√ºtzen.  

![](/static/images/news.png)
*[CC-BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/), [Christoph Hoppenbrock](https://bildbauer.de/), ver√§ndert ([Original](https://demokratielabore.de/workshops/newsbusters/))*

###### ignore please


Wie praktisch w√§re es da, wenn ein Algorithmus einfach die Beleidigungen aus den Kommentaren herausfiltern k√∂nnte. Das ist grundlegend m√∂glich mit dem sogenannten Machine Learning (Maschinelles Lernen). Auf dieser Webseite wird ein Verfahren des Machine Learning am Beispiel von Hasskommentaren erkl√§rt. Der Fokus liegt auf der Verarbeitung von Sprache, die Disziplin hei√üt Computerlinguistik (oder engl. Natural-Language Processing). Machine Learning wird aber auch bei der Verarbeitung von Bildern, z. B. der Gesichtserkennung angewandt.

[Overview1/]

## Was ist Machine Learning?

Mit dem Aufkommen der Informationstechnologie im 20. Jahrhundert wurden immer mehr Entscheidungen an Computer abgegeben. Aufgaben wurden mithilfe von Programmcodes gel√∂st. Ein traditioneller Ansatz: Programmier:innen formulieren einen Algorithmus, der Hasskommentare finden soll. Das k√∂nnte etwa mit einer langen Liste aller beleidigenden W√∂rter funktionieren. Immer dann, wenn ein Wort aus der Liste in einem Kommentar auftaucht, markiert der Algorithmus den Kommentar als Hasskommentar.

Nur l√§sst sich dieser Ansatz leicht austricksen. Hasskommentare, die leichte Abwandlungen beinhalten, erkennt der Algorithmus nicht. Es reicht schon, wenn einzelne Buchstaben durch Zahlen ersetzt werden. Also aus "Beleidigung" wird etwa ‚ÄúBele1digung‚Äù (z. B. "Dummk0pf") und der Kommentar wird nicht als Hasskommentar erkannt. F√ºr den Menschen ist es einfach die Manipulation zu erkennen, f√ºr den Algorithmus ist das nicht m√∂glich, da er sich an die vorgegebene Liste h√§lt. Auch ist es sehr zeitaufwendig, eine solch umfassende Liste anzufertigen, da sich Sprache immer ver√§ndert und immer neue Beleidigungen kreiert werden k√∂nnen. Zudem kommt es auf den Kontext an, ein einzelnes Wort ist eventuell nur im Zusammenhang mit anderen W√∂rtern problematisch.

Diese Probleme k√∂nnten durch die Anwendung von Machine Learning √ºberwunden werden. Mit Machine Learning sollen Computer die Bedeutung von W√∂rtern und ganzen S√§tzen erlernen, damit der Computer die Zusammenh√§nge verstehen kann. Es gibt zwei Arten von Machine Learning:

### 1. √úberwachtes Machine Learning

Beim √ºberwachten Machine Learning geht es darum, den Computerprogramm auf eine Problemstellung einzuspielen, damit er dann innerhalb dieses Rahmens automatisiert Antworten ausspucken kann. Beispielhafter Anwendungsfall f√ºr Bilder: Ein Programm soll erkennen, ob auf Bildern Katzen oder Hunde zu erkennen sind. In einem ersten Schritt m√ºssen die Bilder von einem Menschen benannt werden. Die Bilder werden als Katzen- oder Hundebilder annotiert oder gelabelt. Nur so kann der Computer daraufhin lernen, was auf dem Bild abgebildet ist. Die richtige Antwort ist zun√§chst vorgegeben. Dadurch wei√ü das Programm immer, ob seine eigene Antwort richtig oder falsch ist und er kann seine Parameter anhand dessen anpassen ("trainiert"). Die Parameter eines Programmes sind das Gehirn, sie werden auch als Modell bezeichnet. Im echten Betrieb, soll das Programm mit einem Modell ohne menschliche Hilfe Hunde von Katzen unterscheiden.

### 2. Un√ºberwachtes Machine Learning

Beim un√ºberwachten Machine Learning gibt es diese Vorgaben nicht. Ein Programm wird mit einer gro√üen Menge an Daten gef√ºttert und hat keine spezifischen Anweisungen, was die Daten bedeuten sollen. Zum Beispiel: Ein Programm wird mit automatisch aus dem Internet heruntergeladenen Texten aus digitalen Zeitungsarchiven gef√ºttert. Die Maschine selbst erkundet die Strukturen der Daten und soll f√ºr den Menschen daraus sinnvolle Informationen bilden.

## Klassifikation von Kommentaren

Um nun Hasskommentare automatisiert erkennen zu k√∂nnen, m√ºssen Verfahren aus dem un√ºberwachte und dem √ºberwachte Machine Learning angewandt werden. In einem ersten Schritt wird Sprache in eine f√ºr den Computer verwendbare Form umgewandelt, in Zahlen. Das geschieht durch das un√ºberwachte Machine Learning, bei dem der Algorithmus Milliarden von W√∂rtern analysiert. Aber wie l√§uft das genau ab? 

![](/static/images/computer.png)
*[CC-BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/), [Christoph Hoppenbrock](https://bildbauer.de/), ver√§ndert ([Original](https://demokratielabore.de))*

###### ignore please

 Es geht zun√§chst darum, zu verstehen, wie ein Computer W√∂rter interpretiert.

## Sprache, Computer und Repr√§sentation

W√∂rter sind keine Zahlen, aber ein Computer rechnet nur mit Zahlen. Wie werden also aus W√∂rter Zahlen? Damit ein Computer Text analysieren kann, ben√∂tigt man f√ºr die Auswertung eine gewisse Datenmenge. Je mehr Daten der Algorithmus auswerten kann, umso besser sind die Ergebnisse aus dem Machine Learning. Zun√§chst wird eine gro√üe Mengen an Flie√ütext gebraucht, wie z. B. tausende Nachrichtenartikel. Dann m√ºssen die Trainingsdaten mithilfe eines Programms, eines Tokenizers, in W√∂rter aufgeteilt werden. In einfachen F√§llen wird am Leerzeichen getrennt. Aber schon bei Satzzeichen wird es kompliziert. Zeigt zum Beispiel ein Punkt nun das Ende eines Satzes an oder die Abk√ºrzung eines Wortes? Die Schwierigkeit wird anhand dieses Beispiels deutlich:


[SVG src:"/static/images/tokenizer.svg" /]
*Text wird durch einen Tokenizer in W√∂rter aufgeteilt*

###### ignore please

Durch den Tokenizer sind die Texte in eine Liste von W√∂rtern zerlegt. Im n√§chsten Abschnitt wird erkl√§rt, wie genau die Bedeutung entsteht.

## Word Embeddings: Bedeutung durch Kontext

Bei dem grundlegenden Ansatz geht es um die Frage, welche W√∂rter treten h√§ufig mit anderen W√∂rtern auf, die sogenannte Kollokation von W√∂rtern. Der englische Linguist [John Rupert Firth](https://de.wikipedia.org/wiki/John_Rupert_Firth) hat Mitte des 20. Jahrhunderts, einige √úberlegungen dazu gemacht auf. Diese bilden noch heute das Fundament der Computerlinguistik. Zwei Zitate als Auszug:

[Aside]
> You shall know a word by the company it keeps. 
[/Aside]

> Du sollst ein Wort von seiner Umgebung kennen.

und auch

[Aside]
> The complete meaning of a word is always contextual, and no study of meaning apart from context can be taken seriously. 
[/Aside]

> Die vollst√§ndige Bedeutung eines Wortes ist immer kontextabh√§ngig, und keine kontextunabh√§nige Untersuchungen √ºber Bedeutungen kann ernst genommen werden. 

[Aside]

Quelle: John Rupert Firth "The Technique of Semantics." (1935) "A synopsis of linguistic theory 1930-1955." (1957)

[/Aside]

Durch die Analyse von Kollokation von W√∂rter kann automatisiert die Bedeutung von W√∂rtern abgeleitet werden. Anbei ein Beispiel.


> Ich esse gerne **Fisch**. 

> Ich esse gerne **Bananen**.

> Ich esse gerne **Brot**.

Die drei W√∂rter (Fisch, Bananen, Brot) kommen in √§hnlichen Kontexten vor und daher wei√ü die Maschine, dass die beiden W√∂rter in einem gewissen Ma√üe √§hnlich sind. In diesem Fall, geht es um Lebensmittel. So versteht der Algorithmus, dass diese W√∂rter zur selben Kategorie geh√∂ren.

Es wird √ºber alle S√§tze hinweg gez√§hlt, welche W√∂rter mit welchen anderen W√∂rtern verwendet werden. Als Abstand wird z. B. 2 verwendet: Alle W√∂rter, die maximal zwei W√∂rter Abstand haben, werden gez√§hlt. Ein Beispiel:

[SVG src:"/static/images/window.svg" /]
*Jede Wortpaarung mit einem Abstand von zwei wird gez√§hlt*

###### ignore please

Nach dem Z√§hlen folgen eine [Reihe weiterer mathematischer Schritte](/hintergrund#wie-genau-wurden-die-word-embeddings-erstellt?).
Am Ende entsteht ein sogenannte Word Embedding (‚ÄúWort-Einbettung‚Äù), um Worte in eine Sprache des Rechners (Zahlen) zu √ºbersetzen.
Grunds√§tzlich ordnet ein Word Embeddings jedem Wort eine Reihe von Werten zugeschrieben. Oft sind das lange Zahlenkolonnen zwischen 300 oder 500 Zahlen  pro Wort.
Anhand dieser Zahlenreihen versteht der Algorithmus die Bedeutung der W√∂rter.
So sollen √§hnliche Begriffe auch √§hnliche Zahlenwerte umfassen.
Da der Algorithmus nun den W√∂rten konkrete Zahlen zugeordnet hat, kann mit diesen Werten gerechnet werden.

## Wie gut kann die Maschine Bedeutungen erlernen? Ausprobieren!

Ich habe ein Word Embedding trainiert und gebe hier dir die M√∂glichkeit es auszuprobieren. Die Grundlage bilden √ºber 13 Millionen deutsche Online-Kommentaren von 2010 bis 2019. Es gibt keine reine Zahlendarstellung weil dies nicht anschaulich ist. Jedoch werden zu einem ausgew√§hlen Wort √§hnliche Begriffe angezeigt. *√Ñhnlich* bedeutet hier, dass der Computer (durch das Word Embedding) das so sieht.

## Bitte ein Wort ausw√§hlen

[Radio value:q options:`['auto', 'berlin', 'merkel', 'mittelmeer', 'mieten', 'afd', 'migrant', '√ºberwachung']` /]

oder eigenes Wort eingeben:

[var name:"q" value:"auto" /]
[TextInput value:q  /]

[var name:"chooseQ" value:`{tokens:[]}` /]
[DataLoader value:chooseQ src:`"https://kommentare.vis.one/vectors/typeahead_videos/german_comments_2010_2019_100k?q=" + q + "&n=100"` timeout:300/]

// cut of first token if it's the same

[Radio value:q options:`q === '' ? [] : (chooseQ.tokens[0] == q ? chooseQ.tokens.slice(1) : chooseQ.tokens)` /]

[var name:"qTable" value:`{tokens:[], sims: []}` /]
[DataLoader value:qTable src:`"https://kommentare.vis.one/vectors/sim/german_comments_2010_2019_100k?q=" + (chooseQ.tokens[0] || q) + "&n=10"` timeout:600 /]

[br /]

Die 10 √§hnlichsten W√∂rter zu [Display value:`(chooseQ.tokens[0] ||  q)`/] (so wie es der Computer sieht):

[Table
    data:`qTable.tokens.map((k, i) => ({token: k, sim: qTable.sims[i]}));`
    columns:`[
        {
            Header: 'Wort',
            accessor: 'token',
        },{
            Header: '√Ñhnlichkeit',
            accessor: 'sim',
            Cell: props => (props.row.sim * 100).toFixed(2) + " %",
            getProps: (state, rowInfo, column) => {
                return {
                    style: {
                        background: window.chroma.scale(['white', [42,42,123]])(rowInfo.row.sim),
                        color:  rowInfo.row.sim > 0.4 ? 'white': 'black'
                    },
                };
            },
        }
    ]`
/]

[Infokasten/]

[var name:"nearest_small" value:`{data: [], tokens:[]}` /]
[DataLoader value:nearest_small small:true src:`"https://kommentare.vis.one/vectors/nearest/german_comments_2010_2019_100k?q=" + (chooseQ.tokens[0] || q) + "&n="` timeout:2000/]

[var name:"scrollerIndex" value:0 /]

[Scroller currentStep:scrollerIndex]
  [Graphic]
      [Chart type:`"scatter"` data:`nearest_small.data.slice(0, 1 + scrollerIndex * (nearest_small.data.length === 7 ? 2 : 3))` labels:`nearest_small.tokens.slice(0, 1 + scrollerIndex * (nearest_small.data.length === 7 ? 2 : 3))` theme:scatter-theme size:`() => Math.max(window.screen.width, window.innerWidth) < 768 ? 4: 2` /]
  [/Graphic]

  [Step]#### zu diesem Wort zeigen wir √§hnliche Begriffe [/Step]
  [Step]#### das sind die n√§hesten W√∂rter[/Step]
  [Step]#### mehr W√∂rter[/Step]
  [Step]#### noch mehr W√∂rter [/Step]
[/Scroller]

[hr/]

Das ist nur ein kleiner Auschhnitt aus einem Word Embedding. In dem Word Embedding sind 100.000 W√∂rter enthalten, es ist nur unm√∂glich alle zu zeigen. In der Folge ein gr√∂√üerer Ausschnitt, um mehr auf einmal zu sehen.

[Oder w√§hle ein anderes Wort aus](#bitte-ein-wort-ausw√§hlen)


[hr/]

[var name:"nearest_large" value:`{data: [], tokens:[]}` /]
[DataLoader value:nearest_large src:`"https://kommentare.vis.one/vectors/nearest/german_comments_2010_2019_100k?q=" + (chooseQ.tokens[0] || q) + "&n=100"` timeout:2500 /]

[Graphic fullWidth:true]
  [Chart type:`"scatter"` data:`nearest_large.data` size:`() => Math.max(window.screen.width, window.innerWidth) < 768 ? 4: 2` labels:`[nearest_large.tokens[0]]` theme:scatter-theme events:`[
      {
        target: "data",
        eventHandlers: {
          onMouseOver: () => {
            return [{
              target: "labels",
              mutation: (props) => {
                return {text: nearest_large.tokens[props.index]};
              }
            }];
          },
          onMouseOut: () => {
            return [{
              target: "labels",
              mutation: (props) => {
                return {text: props.index === 0 ? nearest_large.tokens[0] : null}
              }
            }];
          }
        }
      }
    ]`
/]
[/Graphic]

[Conditional if:`nearest_small.data.length !== 7`]
  Mitte der Maus √ºber die Punkte fahren, um die W√∂rter zu sehen. [Oder ein anderes Wort ausw√§hlen](#bitte-ein-wort-ausw√§hlen)
[/Conditional]

[Conditional if:`nearest_small.data.length === 7`]
  Auf mobilen Ger√§ten erfolgt nur eine reduzierte Darstellung. [Ein anderes Wort ausw√§hlen](#bitte-ein-wort-ausw√§hlen)
[/Conditional]

[hr /]


Das war es f√ºr den ersten Teil. F√ºr Interessierte gibt es einen weitern [Exkurs zur Klassifizierung](/hintergrund#wie-genau-werden-mithilfe-von-word-embeddings-kommentare-klassifiziert?). Im n√§chsten Teil wird gezeigt, wie sich die Sprache in den Kommentaren im Laufe der Zeit ver√§nderte.

[üëâ Weiter zu Teil II](/zeit/)

[hr /]

## √úbersicht

* *[Teil I: Einf√ºhrung](/)*
* [Teil II: Ver√§nderung in den Kommentaren](/zeit/)
* [Teil III: Hintergrund zu Daten & Verfahren](/hintergrund/)

[hr /]

[Thanks/]
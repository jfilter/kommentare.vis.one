[meta title:"EinfÃ¼hrung â€“ Kommentare.vis.one" description:"NLP am Beispiel von Online-Kommentaren erklÃ¤rt" /]


[FilterHeader
  subtitle:"Maschinelles Lernen wird als LÃ¶sung verkauft, um Hass aus dem Internet zu filtern. Diese Webseite erklÃ¤rt wie 'die Maschienen' die Bedeutung von WÃ¶rtern erlernen."
  fullWidth:true
  author:"Johannes Filter"
  authorLink:"https://johannesfilter.com"
  date:"15. Februar 2020"
  background:"#222222"
  color:"#ffffff"
/]

[MovingTexts /]

// https://github.com/FormidableLabs/victory/blob/master/packages/victory-core/src/victory-theme/grayscale.js

[derived name:'scatter-theme' value:`{
  axis: {
    style: {
      axis: {
        fill: 'transparent',
        stroke: 'transparent'
      },
      grid: {
        stroke: 'transparent',
      },
      tickLabels: {
        stroke: 'transparent',
        fill: 'transparent'
      }
    }
  },
  scatter: {
    style: {
      data: {
        fill: "black",
        cursor: 'pointer',
        opacity: 0.8
      },
      labels: {
        fontFamily: 'lato',
        fontSize: () => Math.max(window.screen.width, window.innerWidth) < 768 ? 20 :  8,
        letterSpacing: 'normal',
        padding: 3,
        fill: 'charcoal',
        stroke: "transparent"
      }
    }
  }
}` /]

In den Kommentarspalten tobt der Hass. Um diesen einzudÃ¤mmen, prÃ¼fen Zeitungsredaktionen manuell die Kommentare. Doch aufgrund finanzieller EngpÃ¤sse, schlieÃŸen viele Zeitungen die Kommentarfunktion gleich ganz ab. In diesem Kontext gelobt die automatisierte Kommentareauswertung Besserung. Jedoch ist aktuell noch unklar, welche Aufgaben wir den Maschinen Ã¼berlassen wollen. Damit es darÃ¼ber eine gesellschaftliche Debatte gibt, mÃ¼ssen zuerst breite Teile der BevÃ¶lkerung die dahinter liegenden technischen Mechanismen verstehen. Mit dieser Webseite werden einzelne Verfahren des Machinelles Lernens am Beispiel von Kommentaren erklÃ¤rt. Der Fokus liegt auf der Verarbeitung von Sprachen, Computerlinguistik (oder engl. *Natural-Language Processing*) funktioniert.

![](/static/images/news.png)
*[CC-BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/), [Christoph Hoppenbrock](https://bildbauer.de/), verÃ¤ndert ([Original](https://demokratielabore.de/workshops/newsbusters/))*

###### ignore please

## Was ist Maschinelles Lernen?

Mit dem Aufkommen der Informationstechnolgie im 20. Jahrhundert wurden immer mehr Entscheidungen an Computer abgegeben. Aufgaben wurden mithilfe von Programm-Code gelÃ¶st. Programmier:innen formulieren einen sogennanten Algorithmus, welche eine Schritt-fÃ¼r-Schritt-Rezept darstellt. Ã„hnlich zu einem Kochrezept werden Schritte festgelegt. Wie kÃ¶nnte ein Algorithmus aussehen, der Hasskommentare finden sollte? Ein Ansatz:

1. Man schreibt eine lange Liste von Beleidigungen auf.
2. Wenn eine Beleidigung in einem Kommentar vorkommt, wird der Kommentar aussortiert.

Nur lÃ¤sst sich der Ansatz leicht austricksen, in dem man immer neue WÃ¶rter kreiert. AuÃŸderm wÃ¼rde die LÃ¤nge der Liste ausufern. 

In diesem Zusammenhang gibt es eine neue Art Probleme zu LÃ¶sungen. Man fÃ¼ttert den Computer mit Daten und der Computer soll selbst lernen, welche WÃ¶rter als Beleidung zÃ¤hlt. AnsÃ¤tze dieser Art nennt man Maschinelles Lernen (engl. *Machine Learning*). Es gibt zwei Arten von Maschine Learning: 
1. Trainingsdaten werden manuell annotiert und die Maschiene soll lernen von diesen zu extrapolieren ("Ã¼berwachtes Lernen")
2. Es werden keine Daten extra annotiert, sondern von Information auf alten geschlossen werden. ("unÃ¼berwachtes Lernen")

Wir fokussieren auf den 2. Ansatz. Aus einer groÃŸen Menge an Text soll der Computer WÃ¶rter erlernen. Wir sehen uns nicht an, wie Kommentare als Hass klassifiert wird. Es geht zunÃ¤chst darum, zu verstehen, wie die Maschiene WÃ¶rter versteht.

![](/static/images/computer.png)
*[CC-BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/), [Christoph Hoppenbrock](https://bildbauer.de/), verÃ¤ndert ([Original](https://demokratielabore.de))*

###### ignore please

## Sprache, Computer und Representation

FÃ¼r dem Computer gibt es nur Nullen oder Einzen. Entweder Strom flieÃŸt oder nicht. In den Betriebssytemen der Computer sind jedoch Abstraktionsmodelle eingebaut, sodass sich kein Entwickler mit dem FlieÃŸen von Strom beschÃ¤ftigen muss. Wir gehen davon aus, dass Text vorliegt. Im ersten Schritt unterteilen wir den Text in WÃ¶rter.

Mit einem sogennanten Tokenizer wird der Text in  WÃ¶rter aufgeteilt. In einfachen FÃ¤llen, wird am Leerzeichen getrennt. Aber schon bei Satzzeichen wird es kompliziert. Ist ein Punkt nun ein Satzende (und damit das vorherigen Buchstaben ein Wort) oder teile einer AbkÃ¼rzung (und damit nicht zwangslÃ¤ufig ein eigenes Wort)? Die Schwierigkeit erkennt man an diesem Beispiel.

[SVG src:"/static/images/tokenizer.svg" /]
*Text wird durch einen Tokenizer in WÃ¶rter aufgeteilt*

###### ignore please

Jetzt haben wir WÃ¶rter. Im nÃ¤chsten Abschnitt fÃ¼hren wir uns, wie genau die Bedeutung entsteht.

## Bedeutung durch Kontext

Die Grundlegende Ansatz: Die Kolokation von WÃ¶rtern. Also welche WÃ¶rter werden mit welchen anderen WÃ¶rter im gleichen Satz auf. Der englische Linguister [John Rupert Firth](https://en.wikipedia.org/wiki/John_Rupert_Firth) stellt Mitte des 20. Jahrhunerts einige Theoreme auf.

[Aside]
> You shall know a word by the company it keeps. 
[/Aside]

> Du sollst ein Wort von der Begleitung kennen, die sie fÃ¼hrt. 

[Aside]
> The complete meaning of a word is always contextual, and no study of meaning apart from context can be taken seriously. 
[/Aside]

> Die vollstÃ¤ndige Bedeutung eines Wortes ist immer kontextabhÃ¤ngig, und keine Studie Ã¼ber die Bedeutung auÃŸer dem Kontext kann ernst genommen werden. 

Der Kontext entscheidet Ã¼ber die wahre Beudeutung eines Wortes. Und ein Wort kann durch 

[Aside]
> Meaning by collocation is an abstraction at the syntagmatic level and is not directly concerned with the conceptual or idea approach to the meaning of words. One of the meanings of _night_ is its collocability with _dark_, and of _dark_, of course, collocation with _night_.
[/Aside]

> Die Bedeutung durch Kollokation ist eine Abstraktion auf der syntagmatischen Ebene und hat nichts mit der begrifflichen oder ideellen AnnÃ¤herung an die Bedeutung von WÃ¶rtern zu tun. Eine der Bedeutungen von _Nacht_ ist die KollokationsfÃ¤higkeit mit _dunkel_, und von _dunkel_ natÃ¼rlich die Kollokation mit _Nacht_.

Konrekt kann man das den Beispielen verstehen.

> Ich esse gerne **Fisch**. 

> Ich esse gerne **Bananen**.

> Ich esse gerne **Brot**.

Die drei WÃ¶rter kommen in Ã¤hnlichen Kontexten vor und daher weiÃŸ die Maschiene, dass die beiden WÃ¶rter in einem gewissen MaaÃŸe Ã¤hnlich sind. In diesem Fall, geht es um Lebensmitteln. Und so erlernt die Maschiene die WÃ¶rter.

[SVG src:"/static/images/window.svg" /]
*Ãœber jedes Wort wird iteriert*

###### ignore please



Also die Beudeutung kommt nur durch WÃ¶rtern. Mittels matematischer Verfahren wird ermittelt, welche WÃ¶rter in Ã¤hnlichen Kontexten vorkommt. Am Ende hat man ein Modell bei dem man zu jedem Wort 500 Werte von 0 bis 1 hat. Details werden hier nicht erklÃ¤rt. Nur so viel: Es wird ein Matrix aufgestellt, in ertem Schritt gezÃ¤hlt.


## Wie gut KÃ¶nnen Maschiene Sprache verstehen? Mitmachen!

Um besser zu Verstehen, was abgeht jetzt hier was.

Um besser zu verstehen um was es geht, haben wir selbst ein Embedding traniert. Auf XXX kommentaren von Online-Zeitungen. Probieren Sie es aus um es besser zu verstehen.

## Bitte ein Wort auswÃ¤hlen

[Radio value:q options:`['merkel', 'mittelmeer', 'mieten', 'afd', 'migrant', 'Ã¼berwachung']` /]

oder eigenes eingeben:

[var name:"q" value:"merkel" /]
[TextInput value:q  /]

[var name:"chooseQ" value:`{tokens:[]}` /]
[DataLoader value:chooseQ src:`"https://ptf-vecs.app.vis.one/typeahead_videos/german_comments_2010_2019_100k?q=" + q + "&n=100"` timeout:500/]

// cut of first token if it's the same

[Radio value:q options:`q === '' ? [] : (chooseQ.tokens[0] == q ? chooseQ.tokens.slice(1) : chooseQ.tokens)` /]

[var name:"qTable" value:`{tokens:[], sims: []}` /]
[DataLoader value:qTable src:`"https://ptf-vecs.app.vis.one/sim/german_comments_2010_2019_100k?q=" + (chooseQ.tokens[0] || q) + "&n=10"` timeout:1000 /]

[br /]

Die 10 Ã¤hnlichsten WÃ¶rter zu [Display value:`chooseQ.tokens[0]`/]:

[Table
    data:`qTable.tokens.map((k, i) => ({token: k, sim: qTable.sims[i]}));`
    columns:`[
        {
            Header: 'Wort',
            accessor: 'token',
        },{
            Header: 'Ã„hnlichkeit',
            accessor: 'sim',
            Cell: props => (props.row.sim * 100).toFixed(2) + "%",
            getProps: (state, rowInfo, column) => {
                return {
                    style: {
                        background: window.chroma.scale(['white', [42,42,123]])(rowInfo.row.sim),
                        color:  rowInfo.row.sim > 0.4 ? 'white': 'black'
                    },
                };
            },
        }
    ]`
/]

## Strukturen abbilden

Die Ã¤hnlichsten Begriffe als Rank darzustellen, ist ein einfacher Einstieg. Es werden jedoch die Strukturen zwischen den Begriffen verschleiert. Eine Projektion auf die Ebene bietet hier besseren Einblick. Hier ist zu beachten, dass Begriffe desto Ã¤hnlicher sich die Begriffe sind, desto nÃ¤her sind sie zusammen. Die Achsen haben hier keine Bedeutung.

[var name:"nearest_small" value:`{data: [], tokens:[]}` /]
[DataLoader value:nearest_small small:true src:`"https://ptf-vecs.app.vis.one/nearest/german_comments_2010_2019_100k?q=" + (chooseQ.tokens[0] || q) + "&n="` timeout:2000/]

[var name:"scrollerIndex" value:0 /]

[Scroller currentStep:scrollerIndex]
  [Graphic]
      [Chart type:`"scatter"` data:`nearest_small.data.slice(0, 1 + scrollerIndex * (nearest_small.data.length === 7 ? 2 : 3))` labels:`nearest_small.tokens.slice(0, 1 + scrollerIndex * (nearest_small.data.length === 7 ? 2 : 3))` theme:scatter-theme size:`() => Math.max(window.screen.width, window.innerWidth) < 768 ? 4: 2` /]
  [/Graphic]

  [Step]## die nÃ¤hesten[/Step]
  [Step]## mehr[/Step]
  [Step]## noch mehr[/Step]
  [Step]## jetzt all[/Step]
[/Scroller]

[hr/]

In der Folge ein grÃ¶ÃŸerer Ausschnitt. 

Mitte der Maus Ã¼ber die Punkte, um die Namen zu erhalten.

[hr/]

[var name:"nearest_large" value:`{data: [], tokens:[]}` /]
[DataLoader value:nearest_large src:`"https://ptf-vecs.app.vis.one/nearest/german_comments_2010_2019_100k?q=" + (chooseQ.tokens[0] || q) + "&n=100"` timeout:2500 /]

[Graphic fullWidth:true]
  [Chart type:`"scatter"` data:`nearest_large.data` size:`() => Math.max(window.screen.width, window.innerWidth) < 768 ? 4: 2` labels:`[nearest_large.tokens[0]]` theme:scatter-theme events:`[
      {
        target: "data",
        eventHandlers: {
          onMouseOver: () => {
            return [{
              target: "labels",
              mutation: (props) => {
                return {text: nearest_large.tokens[props.index]};
              }
            }];
          },
          onMouseOut: () => {
            return [{
              target: "labels",
              mutation: (props) => {
                return {text: props.index === 0 ? nearest_large.tokens[0] : null}
              }
            }];
          }
        }
      }
    ]`
/]
[/Graphic]

[hr/]


## VerÃ¤nderung Ã¼ber die Zeit

Im weiteren Verlauf haben wir uns angesehen, wie sich die Sprache verÃ¤ndert hat.

[ğŸ‘‰ Weiter mit Teil II](/zeit/)

[hr /]

## Ãœbersicht

* **[Teil I: EinfÃ¼hrung](/)**
* [Teil II: VerÃ¤nderung in den Kommentaren](/zeit/)
* [Teil III: Hintergrund zu Daten & Verfahren](/hintergrund/)

[hr /]

[Thanks/]
[meta title:"Wie Maschinen Kommentare verstehen – Kommentare.vis.one" description:"Maschinelles Lernen wird als Lösung verkauft, um Hass aus dem Internet zu filtern. Diese Webseite erklärt wie 'die Maschinen' die Bedeutung von Wörtern erlernen." url:"https://kommentare.vis.one/" twitterHandle:"@fil_ter" shareImageUrl:"https://kommentare.vis.one/static/images/preview.png" /]


[FilterHeader
  subtitle:"Machine Learning wird als Lösung verkauft, um Hass aus dem Internet zu filtern. Diese Webseite erklärt, wie Computer die Bedeutung von Wörtern erlernen."
  fullWidth:true
  author:"Johannes Filter"
  authorLink:"https://johannesfilter.com"
  date:"15. März 2020"
  background:"#222222"
  color:"#ffffff"
/]

[MovingTexts /]

// https://github.com/FormidableLabs/victory/blob/master/packages/victory-core/src/victory-theme/grayscale.js

[derived name:'scatter-theme' value:`{
  axis: {
    style: {
      axis: {
        fill: 'transparent',
        stroke: 'transparent'
      },
      grid: {
        stroke: 'transparent',
      },
      tickLabels: {
        stroke: 'transparent',
        fill: 'transparent'
      }
    }
  },
  scatter: {
    style: {
      data: {
        fill: "black",
        cursor: 'pointer',
        opacity: 0.8
      },
      labels: {
        fontFamily: 'lato',
        fontSize: () => Math.max(window.screen.width, window.innerWidth) < 768 ? 20 :  8,
        letterSpacing: 'normal',
        padding: 3,
        fill: 'charcoal',
        stroke: "transparent"
      }
    }
  }
}` /]

In den Kommentarspalten tobt der Hass. Um diesen einzudämmen, prüfen Zeitungsredaktionen manuell die Kommentare. Das ist personal- und zeitaufwendig. Und bei manchen Themen, ist es für die Medienhäuser kaum noch möglich, die Vielzahl an Kommentaren zu moderieren. Da wird dann die Kommentarfunktion mitunter einfach ganz abgeschaltet, um sich vor einer Flut an Hass-Kommentaren zu schützen.  

Wie praktisch wäre es da, wenn ein Algorithmus einfach die Beleidigungen aus den Kommentaren herausfiltern könnte. Das ist grundlegend möglich mit dem sogenannten Machine Learning (Maschinelles Lernen). Mit dieser Webseite werden einzelne Verfahren des Machine Learning am
          Beispiel von Kommentaren erklärt. Der Fokus liegt auf der Verarbeitung
          von Sprache. Die Diszipling heißt Computerlinguistik (oder engl.
          Natural-Language Processing). Machine Learning wird auch bei der
          Verarbeitung von Bildern, z. B. der Gesichtserkennung angewandt.
          Darüber geht es hier nicht.

[Overview1/]


![](/static/images/news.png)
*[CC-BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/), [Christoph Hoppenbrock](https://bildbauer.de/), verändert ([Original](https://demokratielabore.de/workshops/newsbusters/))*

###### ignore please

## Was ist Machine Learning?

Mit dem Aufkommen der Informationstechnologie im 20. Jahrhundert wurden immer mehr Entscheidungen an Computer abgegeben. Aufgaben wurden mithilfe von Programm-Codes gelöst. Programmier:innen formulieren einen sogennannten Algorithmus, welches eine Schritt-für-Schritt-Rezept darstellt. Ähnlich zu einem Kochrezept werden Schritte festgelegt. Wie könnte ein Algorithmus aussehen, der Hasskommentare finden sollte? Ein Ansatz:

1. Man schreibt eine lange Liste von Beleidigungen auf.
2. Wenn eine Beleidigung in einem Kommentar vorkommt, wird der Kommentar aussortiert.

Nur lässt sich der Ansatz leicht austricksen. Hasskommentare die leichte Abwandlungen beinhalter, würde durchs Raster fallen. Zum Beispiel könnten Trolle einzelne Buchstaben durch Zahlen ersetzen. Aus Beleidigung wird Bele1digung. Für den Menschen ist es einfach die Manipulation zuerkennen, für den Computer schwer. Außerderm würde die Länge der Liste ausufern. Und dann heißt es nicht, dass nicht jedes mal, wenn ein bestimmte Beleidung auftaucht, diese auch negativ gemeint ist. So würde es viele falsche Treffer geben.

Mit dem Maschinellen Lernen möchte man, dem Computer die Bedeutung von Wörtern erlernen lassen, sodass der Computer die Zusammenhänge verstehen kann. Man füttert den Computer mit Daten und der Computer soll selbst lernen, welche Wörter als Beleidigung eingeordnet werden sollen. Das nennt man Machine Learning (engl. Machine Learning). Es gibt zwei Arten von Maschinellem Lernen.

### 1. Unüberwachtes Machine Learning

Für Verfahren dieser Art werden zum Beispiel große Textmengen werden aus dem Internet automatisiert heruntergeladen. Oder stammen z. B. von Artikeln aus digitalen Zeitungsarchiven. Verfahren dieser Art, benötigen kein inspizieren bzw. annotieren der Daten durch Menschen. Das Überwachen bezieht sich auf den Menschen.

### 2. Überwachtes Machine Learning

Bei Verfahren dieser Art, müssen Daten im 1. Schritt manuell begutachtet werden. Diese Begutachten bedeutet, dass Text von Menschen angesehen wird. Oft wird der gleiche Text von mehrer Menschen begutachtet, um ein finales Gutachten zu erreichen. Dann im weiteren Verlauf soll versucht werden, dass der Computer es lernt, von den annotierten Daten auf neues zu extrapolieren. Das Überwacht bezieht sich darauf, dass von Menschen manuell Daten begutachtet wurden.

## Klassifikation von Kommentaren

Für die automatisierte Klassifikation auf Kommentaren sind beide Notwendig. Mittels unüberwachtes Lernen wird dem Computer allgemein erklärt, was Sprache ist. Das geschieht auf großen Mengen von Text, Milliarden von Wörtern.

In einem zweiten Schritt wird dann mittels überwachtem Machine Learning dem Computer beigebracht, was Hass-Kommentare sind. Dazu bedarf es in der Regel sehr viel weniger Wörtern.

![](/static/images/computer.png)
*[CC-BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/), [Christoph Hoppenbrock](https://bildbauer.de/), verändert ([Original](https://demokratielabore.de))*

###### ignore please

 Es geht zunächst darum, zu verstehen, wie ein Computer Wörter interpretiert.

## Sprache, Computer und Representation

In diesem Abschnitt geht es darum, wie nun ein Computer mit Wörtern arbeitet. Damit dieser Text anaylsieren kann, benötigt man für die Auswertung eine gewisse Datenmenge. Je mehr Daten, umso besser für das maschinelle Lernen. In meinem konkreten Fall habe ich Kommentare verwendet aus der Kommentarspalte von Zeit-Online. Ich habe eine Anzahl von über 13 Millionen Kommentaren analysiert.

Zunächs müssen die Trainingsdaten, hier die 13 Millionen Kommentaren, mithilfe eines Tokenizers in Wörter aufgeteilt werden. In einfachen Fällen, wird am Leerzeichen getrennt. Aber schon bei Satzzeichen wird es kompliziert. Zeigt zum Beispiel ein Punkt nun das Ende eines Satzes an oder die Abkürzung eines Wortes? Die Schwierigkeit wird anhand dieses Beispiels deutlich:


[SVG src:"/static/images/tokenizer.svg" /]
*Text wird durch einen Tokenizer in Wörter aufgeteilt*

###### ignore please

Jetzt haben wir Wörter. Für die Weiterverarbeitung muss der Text als eine Liste von Wörtern vorliegen. Im nächsten Abschnitt schauen wir uns an, wie genau die Bedeutung entsteht. 

## Word Embeddings: Bedeutung durch Kontext

Bei dem grundlegende Ansatz geht es um die Frage, welche Wörter treten häufig mit anderen Wörtern auf, die sogenannte Kollokation von Wörtern. Der englische Linguist [John Rupert Firth](https://en.wikipedia.org/wiki/John_Rupert_Firth) hat Mitte des 20. Jahrhunderts, einige Feststellungen dazu gemacht auf. Diese bilden noch heute die Basis für  das Fundament der  Computerlinguistik.


[Aside]
> You shall know a word by the company it keeps. 
[/Aside]

> Du sollst ein Wort von der Begleitung (Umgebung) kennen, das es führt.

Quelle: John Rupert Firth (1957). "A synopsis of linguistic theory 1930-1955." In Special Volume of the Philological Society. Oxford: Oxford University Press.;

[Aside]
> The complete meaning of a word is always contextual, and no study of meaning apart from context can be taken seriously. 
[/Aside]

> Die vollständige Bedeutung eines Wortes ist immer kontextabhängig, und keine Studie über die Bedeutung außer dem Kontext kann ernst genommen werden. 

Quelle: J. R. Firth (1935). "The Technique of Semantics." Transactions of the Philological Society, 36-72; p. 37 (Reprinted in Firth (1957) Papers in Linguistics. London: Oxford University Press, 7-33).

[Aside]
> Meaning by collocation is an abstraction at the syntagmatic level and is not directly concerned with the conceptual or idea approach to the meaning of words. One of the meanings of _night_ is its collocability with _dark_, and of _dark_, of course, collocation with _night_.
[/Aside]

> Die Bedeutung durch Kollokation ist eine Abstraktion auf der syntagmatischen Ebene und hat nichts mit der begrifflichen oder ideellen Annäherung an die Bedeutung von Wörtern zu tun. Eine der Bedeutungen von _Nacht_ ist die Kollokationsfähigkeit mit _dunkel_, und von _dunkel_ natürlich die Kollokation mit _Nacht_.

Quelle: John Rupert Firth (1957). "A synopsis of linguistic theory 1930-1955." In Special Volume of the Philological Society. Oxford: Oxford University Press.;


Der Kontext entscheidet also über die tatsächliche Bedeutung eines Wortes. Konkret kann man das an den folgenden Beispielen verstehen.

> Ich esse gerne **Fisch**. 

> Ich esse gerne **Bananen**.

> Ich esse gerne **Brot**.

Die drei Wörter kommen in ähnlichen Kontexten vor und daher weiß die Maschine, dass die beiden Wörter in einem gewissen Maaße ähnlich sind. In diesem Fall, geht es um Lebensmitteln. Und so erlernt die Maschine die Wörter.

So weit so gut, doch ein Rechner arbeitet nur mit Einsen und Nullen. Um also Worte in eine Sprache des Rechners zu übersetzen, benutzt man das Word Embedding (“Wort-Einbettung”). Jedem Wort wird eine Reihe von Werten zugeschrieben. Es wird über alle Sätze hinweg gezählt, welche Wörter mit welchen anderen Wörtern innerhalb eines gewissen Abstands vorkommen. Als Abstand wird z. B. 2 Verwendelt. Alle Wörter, die maximal zwei Wörter Abstand haben, werden gezählt. Ein Beispiel:

[SVG src:"/static/images/window.svg" /]
*Jede Wortpaarung mit einem Abstand von zwei wird gezählt.*

###### ignore please

Nach dem Zählen, folgen eine reihen weiterer Schritte, [die hier näher beschrieben werden](/). Grundsätzlich entsteht am Ende eine Word Embeddings, welches jedem Wort mehrer Zahlenwerden zuordnet. Oft zwischen 300 oder 500 Zahlenwerden. Diese sind sogennten Dimensionen. Mithilfe dieser Zahlen wird die Bedeutung zugewiesen. So sollen ähnliche Begriffe auch ähnliche Zahlenwerte umfassen. Etliche wissenschaftliche Studien haben gezeigt, dass so zumindestens Teile einer Sprache erechnet werden kann.

## Wie gut kann die Maschine Bedeutungen erlernen? Ausprobieren!

Wir haben nun ein Word Embedding trainiert und geben hier dir die Möglichkeit es auszuprobieren. Die Grundlage waren die über 13 Millionen deutschen Online-Kommentaren.

## Bitte ein Wort auswählen

[Radio value:q options:`['merkel', 'mittelmeer', 'mieten', 'afd', 'migrant', 'überwachung']` /]

oder eigenes Wort eingeben:

[var name:"q" value:"merkel" /]
[TextInput value:q  /]

[var name:"chooseQ" value:`{tokens:[]}` /]
[DataLoader value:chooseQ src:`"https://ptf-vecs.app.vis.one/typeahead_videos/german_comments_2010_2019_100k?q=" + q + "&n=100"` timeout:500/]

// cut of first token if it's the same

[Radio value:q options:`q === '' ? [] : (chooseQ.tokens[0] == q ? chooseQ.tokens.slice(1) : chooseQ.tokens)` /]

[var name:"qTable" value:`{tokens:[], sims: []}` /]
[DataLoader value:qTable src:`"https://ptf-vecs.app.vis.one/sim/german_comments_2010_2019_100k?q=" + (chooseQ.tokens[0] || q) + "&n=10"` timeout:1000 /]

[br /]

Die 10 ähnlichsten Wörter zu [Display value:`(chooseQ.tokens[0] ||  q)`/]:

[Table
    data:`qTable.tokens.map((k, i) => ({token: k, sim: qTable.sims[i]}));`
    columns:`[
        {
            Header: 'Wort',
            accessor: 'token',
        },{
            Header: 'Ähnlichkeit',
            accessor: 'sim',
            Cell: props => (props.row.sim * 100).toFixed(2) + "%",
            getProps: (state, rowInfo, column) => {
                return {
                    style: {
                        background: window.chroma.scale(['white', [42,42,123]])(rowInfo.row.sim),
                        color:  rowInfo.row.sim > 0.4 ? 'white': 'black'
                    },
                };
            },
        }
    ]`
/]

[Infokasten/]

[var name:"nearest_small" value:`{data: [], tokens:[]}` /]
[DataLoader value:nearest_small small:true src:`"https://ptf-vecs.app.vis.one/nearest/german_comments_2010_2019_100k?q=" + (chooseQ.tokens[0] || q) + "&n="` timeout:2000/]

[var name:"scrollerIndex" value:0 /]

[Scroller currentStep:scrollerIndex]
  [Graphic]
      [Chart type:`"scatter"` data:`nearest_small.data.slice(0, 1 + scrollerIndex * (nearest_small.data.length === 7 ? 2 : 3))` labels:`nearest_small.tokens.slice(0, 1 + scrollerIndex * (nearest_small.data.length === 7 ? 2 : 3))` theme:scatter-theme size:`() => Math.max(window.screen.width, window.innerWidth) < 768 ? 4: 2` /]
  [/Graphic]

  [Step]#### nur der Fokus [/Step]
  [Step]#### die nähesten Wörter[/Step]
  [Step]#### mehr Wörter[/Step]
  [Step]#### noch mehr Wörter[/Step]
[/Scroller]

[hr/]

Das ist nur ein Auschhnitt. In dem Word Embedding sind 100.000 Wörter enthalten. Es ist nur unmöglich alle zu zeigen. Deswegen ist es besser nur Ausschnitt zu betrachten.  In der Folge ein größere Ausschnitt. [Oder ein anderes Wort auswählen](#bitte-ein-wort-auswählen)


[hr/]

[var name:"nearest_large" value:`{data: [], tokens:[]}` /]
[DataLoader value:nearest_large src:`"https://ptf-vecs.app.vis.one/nearest/german_comments_2010_2019_100k?q=" + (chooseQ.tokens[0] || q) + "&n=100"` timeout:2500 /]

[Graphic fullWidth:true]
  [Chart type:`"scatter"` data:`nearest_large.data` size:`() => Math.max(window.screen.width, window.innerWidth) < 768 ? 4: 2` labels:`[nearest_large.tokens[0]]` theme:scatter-theme events:`[
      {
        target: "data",
        eventHandlers: {
          onMouseOver: () => {
            return [{
              target: "labels",
              mutation: (props) => {
                return {text: nearest_large.tokens[props.index]};
              }
            }];
          },
          onMouseOut: () => {
            return [{
              target: "labels",
              mutation: (props) => {
                return {text: props.index === 0 ? nearest_large.tokens[0] : null}
              }
            }];
          }
        }
      }
    ]`
/]
[/Graphic]

[Conditional if:`nearest_small.data.length !== 7`]
  Mitte der Maus über die Punkte fahren, um die Wörter zu sehen. [Oder ein anderes Wort auswählen](#bitte-ein-wort-auswählen)
[/Conditional]

[Conditional if:`nearest_small.data.length === 7`]
  [Ein anderes Wort auswählen](#bitte-ein-wort-auswählen)
[/Conditional]

[hr/]

### Erkennung von Hasskommentaren

Okay, jetzt nachdem wir dem Computer die Bedeutung beigebracht haben, wollen wir verstehen, wie der Computer entscheidet, ob es sich um einen Hasskommentare handelt oder nicht? Dafür müssen zunächst Kommentare manuell annotiert werden. Das heißt Menschen entscheiden gemeinsam über eine Trainingsmenge, was ein Hasskommentar ist und was nicht. Dann baut man ein zweistufiges Verfahren. Im ersten überführt man die Kommentare in Zahlen. Dies geschieht mittels Word Embeddings. Aufbauend auf das Word Embedding folgt ein Modell. Und dieses Modell wird mithilfe der Trainingsdaten trainiert. Es gibt hier viele unterschiedliche Verfahren. Am Bekanntesten sind künstliche neuronale Netze. Da ist es so, dass ein Modell bestraft wird, wenn es Fehler macht. Das Modell  wird also aus den annotierten Trainingsdaten gefüttert. Wenn das Modell die richtige Antwort gibt, passiert nichts. Wenn es aber die falsche gibt, also ein Hasskommentare als nicht Hass eingestuft, dann wird das Modell automatisiert angepasst. Dies passiert solange, bis das Modell fertig trainiert ist. In der Folge hat man ein fertig geschultes Modell  das man gezielt einsetzen kann. In der Theorie soll es dann in der Lage sein, auch bei neuen und bislang unbekannten Daten zwischen Beleidigungen und nicht-Beleidigungen unterscheiden zu können. 

[SVG src:"/static/images/ml.svg" /]
*Der Kommentar links unten (rot) wird in das Modell gefüttert. Wenn das Modell den Kommentar so wie Menschen bewertet, passiert nichts. Mach das Modell einen Fehler, wird es angepasst.*

###### ignore please


## Veränderung über die Zeit

Im nächsten Teil zeige ich Ihnen,, wie sich Sprache im Laufe der Zeit verändert.

[👉 Weiter mit Teil II](/zeit/)

[hr /]

## Übersicht

* **[Teil I: Einführung](/)**
* [Teil II: Veränderung in den Kommentaren](/zeit/)
* [Teil III: Hintergrund zu Daten & Verfahren](/hintergrund/)

[hr /]

[Thanks/]
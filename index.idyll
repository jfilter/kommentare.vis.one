[meta title:"Wie Maschinen Kommentare verstehen ‚Äì Kommentare.vis.one" description:"Maschinelles Lernen wird als L√∂sung verkauft, um Hass aus dem Internet zu filtern. Diese Webseite erkl√§rt wie 'die Maschinen' die Bedeutung von W√∂rtern erlernen." url:"https://kommentare.vis.one/" twitterHandle:"@fil_ter" shareImageUrl:"https://kommentare.vis.one/static/images/preview.png" /]


[FilterHeader
  subtitle:"Machine Learning wird als L√∂sung verkauft, um Hass aus dem Internet zu filtern. Diese Webseite erkl√§rt, wie Computer die Bedeutung von W√∂rtern erlernen."
  fullWidth:true
  author:"Johannes Filter"
  authorLink:"https://johannesfilter.com"
  date:"15. M√§rz 2020"
  background:"#222222"
  color:"#ffffff"
/]

[MovingTexts /]

// https://github.com/FormidableLabs/victory/blob/master/packages/victory-core/src/victory-theme/grayscale.js

[derived name:'scatter-theme' value:`{
  axis: {
    style: {
      axis: {
        fill: 'transparent',
        stroke: 'transparent'
      },
      grid: {
        stroke: 'transparent',
      },
      tickLabels: {
        stroke: 'transparent',
        fill: 'transparent'
      }
    }
  },
  scatter: {
    style: {
      data: {
        fill: "black",
        cursor: 'pointer',
        opacity: 0.8
      },
      labels: {
        fontFamily: 'lato',
        fontSize: () => Math.max(window.screen.width, window.innerWidth) < 768 ? 20 :  8,
        letterSpacing: 'normal',
        padding: 3,
        fill: 'charcoal',
        stroke: "transparent"
      }
    }
  }
}` /]

In den Kommentarspalten tobt der Hass. Um diesen einzud√§mmen, pr√ºfen Zeitungsredaktionen manuell die Kommentare. Das ist personal- und zeitaufwendig. Und bei manchen Themen, ist es f√ºr die Medienh√§user kaum noch m√∂glich, die Vielzahl an Kommentaren zu moderieren. Da wird dann die Kommentarfunktion mitunter einfach ganz abgeschaltet, um sich vor einer Flut an Hass-Kommentaren zu sch√ºtzen.  

Wie praktisch w√§re es da, wenn ein Algorithmus einfach die Beleidigungen aus den Kommentaren herausfiltern k√∂nnte. Das ist grundlegend m√∂glich mit dem sogenannten Machine Learning (Maschinelles Lernen). Mit dieser Webseite werden einzelne Verfahren des Machine Learning am
          Beispiel von Kommentaren erkl√§rt. Der Fokus liegt auf der Verarbeitung
          von Sprache. Die Diszipling hei√üt Computerlinguistik (oder engl.
          Natural-Language Processing). Machine Learning wird auch bei der
          Verarbeitung von Bildern, z. B. der Gesichtserkennung angewandt.
          Dar√ºber geht es hier nicht.

[Overview1/]


![](/static/images/news.png)
*[CC-BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/), [Christoph Hoppenbrock](https://bildbauer.de/), ver√§ndert ([Original](https://demokratielabore.de/workshops/newsbusters/))*

###### ignore please

## Was ist Machine Learning?

Mit dem Aufkommen der Informationstechnologie im 20. Jahrhundert wurden immer mehr Entscheidungen an Computer abgegeben. Aufgaben wurden mithilfe von Programm-Codes gel√∂st. Programmier:innen formulieren einen sogennannten Algorithmus, welches eine Schritt-f√ºr-Schritt-Rezept darstellt. √Ñhnlich zu einem Kochrezept werden Schritte festgelegt. Wie k√∂nnte ein Algorithmus aussehen, der Hasskommentare finden sollte? Ein Ansatz:

1. Man schreibt eine lange Liste von Beleidigungen auf.
2. Wenn eine Beleidigung in einem Kommentar vorkommt, wird der Kommentar aussortiert.

Nur l√§sst sich der Ansatz leicht austricksen. Hasskommentare die leichte Abwandlungen beinhalter, w√ºrde durchs Raster fallen. Zum Beispiel k√∂nnten Trolle einzelne Buchstaben durch Zahlen ersetzen. Aus Beleidigung wird Bele1digung. F√ºr den Menschen ist es einfach die Manipulation zuerkennen, f√ºr den Computer schwer. Au√üerderm w√ºrde die L√§nge der Liste ausufern. Und dann hei√üt es nicht, dass nicht jedes mal, wenn ein bestimmte Beleidung auftaucht, diese auch negativ gemeint ist. So w√ºrde es viele falsche Treffer geben.

Mit dem Maschinellen Lernen m√∂chte man, dem Computer die Bedeutung von W√∂rtern erlernen lassen, sodass der Computer die Zusammenh√§nge verstehen kann. Man f√ºttert den Computer mit Daten und der Computer soll selbst lernen, welche W√∂rter als Beleidigung eingeordnet werden sollen. Das nennt man Machine Learning (engl. Machine Learning). Es gibt zwei Arten von Maschinellem Lernen.

### 1. Un√ºberwachtes Machine Learning

F√ºr Verfahren dieser Art werden zum Beispiel gro√üe Textmengen werden aus dem Internet automatisiert heruntergeladen. Oder stammen z. B. von Artikeln aus digitalen Zeitungsarchiven. Verfahren dieser Art, ben√∂tigen kein inspizieren bzw. annotieren der Daten durch Menschen. Das √úberwachen bezieht sich auf den Menschen.

### 2. √úberwachtes Machine Learning

Bei Verfahren dieser Art, m√ºssen Daten im 1. Schritt manuell begutachtet werden. Diese Begutachten bedeutet, dass Text von Menschen angesehen wird. Oft wird der gleiche Text von mehrer Menschen begutachtet, um ein finales Gutachten zu erreichen. Dann im weiteren Verlauf soll versucht werden, dass der Computer es lernt, von den annotierten Daten auf neues zu extrapolieren. Das √úberwacht bezieht sich darauf, dass von Menschen manuell Daten begutachtet wurden.

## Klassifikation von Kommentaren

F√ºr die automatisierte Klassifikation auf Kommentaren sind beide Notwendig. Mittels un√ºberwachtes Lernen wird dem Computer allgemein erkl√§rt, was Sprache ist. Das geschieht auf gro√üen Mengen von Text, Milliarden von W√∂rtern.

In einem zweiten Schritt wird dann mittels √ºberwachtem Machine Learning dem Computer beigebracht, was Hass-Kommentare sind. Dazu bedarf es in der Regel sehr viel weniger W√∂rtern.

![](/static/images/computer.png)
*[CC-BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/), [Christoph Hoppenbrock](https://bildbauer.de/), ver√§ndert ([Original](https://demokratielabore.de))*

###### ignore please

 Es geht zun√§chst darum, zu verstehen, wie ein Computer W√∂rter interpretiert.

## Sprache, Computer und Representation

In diesem Abschnitt geht es darum, wie nun ein Computer mit W√∂rtern arbeitet. Damit dieser Text anaylsieren kann, ben√∂tigt man f√ºr die Auswertung eine gewisse Datenmenge. Je mehr Daten, umso besser f√ºr das maschinelle Lernen. In meinem konkreten Fall habe ich Kommentare verwendet aus der Kommentarspalte von Zeit-Online. Ich habe eine Anzahl von √ºber 13 Millionen Kommentaren analysiert.

Zun√§chs m√ºssen die Trainingsdaten, hier die 13 Millionen Kommentaren, mithilfe eines Tokenizers in W√∂rter aufgeteilt werden. In einfachen F√§llen, wird am Leerzeichen getrennt. Aber schon bei Satzzeichen wird es kompliziert. Zeigt zum Beispiel ein Punkt nun das Ende eines Satzes an oder die Abk√ºrzung eines Wortes? Die Schwierigkeit wird anhand dieses Beispiels deutlich:


[SVG src:"/static/images/tokenizer.svg" /]
*Text wird durch einen Tokenizer in W√∂rter aufgeteilt*

###### ignore please

Jetzt haben wir W√∂rter. F√ºr die Weiterverarbeitung muss der Text als eine Liste von W√∂rtern vorliegen. Im n√§chsten Abschnitt schauen wir uns an, wie genau die Bedeutung entsteht. 

## Word Embeddings: Bedeutung durch Kontext

Bei dem grundlegende Ansatz geht es um die Frage, welche W√∂rter treten h√§ufig mit anderen W√∂rtern auf, die sogenannte Kollokation von W√∂rtern. Der englische Linguist [John Rupert Firth](https://en.wikipedia.org/wiki/John_Rupert_Firth) hat Mitte des 20. Jahrhunderts, einige Feststellungen dazu gemacht auf. Diese bilden noch heute die Basis f√ºr  das Fundament der  Computerlinguistik.


[Aside]
> You shall know a word by the company it keeps. 
[/Aside]

> Du sollst ein Wort von der Begleitung (Umgebung) kennen, das es f√ºhrt.

Quelle: John Rupert Firth (1957). "A synopsis of linguistic theory 1930-1955." In Special Volume of the Philological Society. Oxford: Oxford University Press.;

[Aside]
> The complete meaning of a word is always contextual, and no study of meaning apart from context can be taken seriously. 
[/Aside]

> Die vollst√§ndige Bedeutung eines Wortes ist immer kontextabh√§ngig, und keine Studie √ºber die Bedeutung au√üer dem Kontext kann ernst genommen werden. 

Quelle: J. R. Firth (1935). "The Technique of Semantics." Transactions of the Philological Society, 36-72; p. 37 (Reprinted in Firth (1957) Papers in Linguistics. London: Oxford University Press, 7-33).

[Aside]
> Meaning by collocation is an abstraction at the syntagmatic level and is not directly concerned with the conceptual or idea approach to the meaning of words. One of the meanings of _night_ is its collocability with _dark_, and of _dark_, of course, collocation with _night_.
[/Aside]

> Die Bedeutung durch Kollokation ist eine Abstraktion auf der syntagmatischen Ebene und hat nichts mit der begrifflichen oder ideellen Ann√§herung an die Bedeutung von W√∂rtern zu tun. Eine der Bedeutungen von _Nacht_ ist die Kollokationsf√§higkeit mit _dunkel_, und von _dunkel_ nat√ºrlich die Kollokation mit _Nacht_.

Quelle: John Rupert Firth (1957). "A synopsis of linguistic theory 1930-1955." In Special Volume of the Philological Society. Oxford: Oxford University Press.;


Der Kontext entscheidet also √ºber die tats√§chliche Bedeutung eines Wortes. Konkret kann man das an den folgenden Beispielen verstehen.

> Ich esse gerne **Fisch**. 

> Ich esse gerne **Bananen**.

> Ich esse gerne **Brot**.

Die drei W√∂rter kommen in √§hnlichen Kontexten vor und daher wei√ü die Maschine, dass die beiden W√∂rter in einem gewissen Maa√üe √§hnlich sind. In diesem Fall, geht es um Lebensmitteln. Und so erlernt die Maschine die W√∂rter.

So weit so gut, doch ein Rechner arbeitet nur mit Einsen und Nullen. Um also Worte in eine Sprache des Rechners zu √ºbersetzen, benutzt man das Word Embedding (‚ÄúWort-Einbettung‚Äù). Jedem Wort wird eine Reihe von Werten zugeschrieben. Es wird √ºber alle S√§tze hinweg gez√§hlt, welche W√∂rter mit welchen anderen W√∂rtern innerhalb eines gewissen Abstands vorkommen. Als Abstand wird z. B. 2 Verwendelt. Alle W√∂rter, die maximal zwei W√∂rter Abstand haben, werden gez√§hlt. Ein Beispiel:

[SVG src:"/static/images/window.svg" /]
*Jede Wortpaarung mit einem Abstand von zwei wird gez√§hlt.*

###### ignore please

Nach dem Z√§hlen, folgen eine reihen weiterer Schritte, [die hier n√§her beschrieben werden](/). Grunds√§tzlich entsteht am Ende eine Word Embeddings, welches jedem Wort mehrer Zahlenwerden zuordnet. Oft zwischen 300 oder 500 Zahlenwerden. Diese sind sogennten Dimensionen. Mithilfe dieser Zahlen wird die Bedeutung zugewiesen. So sollen √§hnliche Begriffe auch √§hnliche Zahlenwerte umfassen. Etliche wissenschaftliche Studien haben gezeigt, dass so zumindestens Teile einer Sprache erechnet werden kann.

## Wie gut kann die Maschine Bedeutungen erlernen? Ausprobieren!

Wir haben nun ein Word Embedding trainiert und geben hier dir die M√∂glichkeit es auszuprobieren. Die Grundlage waren die √ºber 13 Millionen deutschen Online-Kommentaren.

## Bitte ein Wort ausw√§hlen

[Radio value:q options:`['merkel', 'mittelmeer', 'mieten', 'afd', 'migrant', '√ºberwachung']` /]

oder eigenes Wort eingeben:

[var name:"q" value:"merkel" /]
[TextInput value:q  /]

[var name:"chooseQ" value:`{tokens:[]}` /]
[DataLoader value:chooseQ src:`"https://ptf-vecs.app.vis.one/typeahead_videos/german_comments_2010_2019_100k?q=" + q + "&n=100"` timeout:500/]

// cut of first token if it's the same

[Radio value:q options:`q === '' ? [] : (chooseQ.tokens[0] == q ? chooseQ.tokens.slice(1) : chooseQ.tokens)` /]

[var name:"qTable" value:`{tokens:[], sims: []}` /]
[DataLoader value:qTable src:`"https://ptf-vecs.app.vis.one/sim/german_comments_2010_2019_100k?q=" + (chooseQ.tokens[0] || q) + "&n=10"` timeout:1000 /]

[br /]

Die 10 √§hnlichsten W√∂rter zu [Display value:`(chooseQ.tokens[0] ||  q)`/]:

[Table
    data:`qTable.tokens.map((k, i) => ({token: k, sim: qTable.sims[i]}));`
    columns:`[
        {
            Header: 'Wort',
            accessor: 'token',
        },{
            Header: '√Ñhnlichkeit',
            accessor: 'sim',
            Cell: props => (props.row.sim * 100).toFixed(2) + "%",
            getProps: (state, rowInfo, column) => {
                return {
                    style: {
                        background: window.chroma.scale(['white', [42,42,123]])(rowInfo.row.sim),
                        color:  rowInfo.row.sim > 0.4 ? 'white': 'black'
                    },
                };
            },
        }
    ]`
/]

[Infokasten/]

[var name:"nearest_small" value:`{data: [], tokens:[]}` /]
[DataLoader value:nearest_small small:true src:`"https://ptf-vecs.app.vis.one/nearest/german_comments_2010_2019_100k?q=" + (chooseQ.tokens[0] || q) + "&n="` timeout:2000/]

[var name:"scrollerIndex" value:0 /]

[Scroller currentStep:scrollerIndex]
  [Graphic]
      [Chart type:`"scatter"` data:`nearest_small.data.slice(0, 1 + scrollerIndex * (nearest_small.data.length === 7 ? 2 : 3))` labels:`nearest_small.tokens.slice(0, 1 + scrollerIndex * (nearest_small.data.length === 7 ? 2 : 3))` theme:scatter-theme size:`() => Math.max(window.screen.width, window.innerWidth) < 768 ? 4: 2` /]
  [/Graphic]

  [Step]#### nur der Fokus [/Step]
  [Step]#### die n√§hesten W√∂rter[/Step]
  [Step]#### mehr W√∂rter[/Step]
  [Step]#### noch mehr W√∂rter[/Step]
[/Scroller]

[hr/]

Das ist nur ein Auschhnitt. In dem Word Embedding sind 100.000 W√∂rter enthalten. Es ist nur unm√∂glich alle zu zeigen. Deswegen ist es besser nur Ausschnitt zu betrachten.  In der Folge ein gr√∂√üere Ausschnitt. [Oder ein anderes Wort ausw√§hlen](#bitte-ein-wort-ausw√§hlen)


[hr/]

[var name:"nearest_large" value:`{data: [], tokens:[]}` /]
[DataLoader value:nearest_large src:`"https://ptf-vecs.app.vis.one/nearest/german_comments_2010_2019_100k?q=" + (chooseQ.tokens[0] || q) + "&n=100"` timeout:2500 /]

[Graphic fullWidth:true]
  [Chart type:`"scatter"` data:`nearest_large.data` size:`() => Math.max(window.screen.width, window.innerWidth) < 768 ? 4: 2` labels:`[nearest_large.tokens[0]]` theme:scatter-theme events:`[
      {
        target: "data",
        eventHandlers: {
          onMouseOver: () => {
            return [{
              target: "labels",
              mutation: (props) => {
                return {text: nearest_large.tokens[props.index]};
              }
            }];
          },
          onMouseOut: () => {
            return [{
              target: "labels",
              mutation: (props) => {
                return {text: props.index === 0 ? nearest_large.tokens[0] : null}
              }
            }];
          }
        }
      }
    ]`
/]
[/Graphic]

[Conditional if:`nearest_small.data.length !== 7`]
  Mitte der Maus √ºber die Punkte fahren, um die W√∂rter zu sehen. [Oder ein anderes Wort ausw√§hlen](#bitte-ein-wort-ausw√§hlen)
[/Conditional]

[Conditional if:`nearest_small.data.length === 7`]
  [Ein anderes Wort ausw√§hlen](#bitte-ein-wort-ausw√§hlen)
[/Conditional]

[hr/]

### Erkennung von Hasskommentaren

Okay, jetzt nachdem wir dem Computer die Bedeutung beigebracht haben, wollen wir verstehen, wie der Computer entscheidet, ob es sich um einen Hasskommentare handelt oder nicht? Daf√ºr m√ºssen zun√§chst Kommentare manuell annotiert werden. Das hei√üt Menschen entscheiden gemeinsam √ºber eine Trainingsmenge, was ein Hasskommentar ist und was nicht. Dann baut man ein zweistufiges Verfahren. Im ersten √ºberf√ºhrt man die Kommentare in Zahlen. Dies geschieht mittels Word Embeddings. Aufbauend auf das Word Embedding folgt ein Modell. Und dieses Modell wird mithilfe der Trainingsdaten trainiert. Es gibt hier viele unterschiedliche Verfahren. Am Bekanntesten sind k√ºnstliche neuronale Netze. Da ist es so, dass ein Modell bestraft wird, wenn es Fehler macht. Das Modell  wird also aus den annotierten Trainingsdaten gef√ºttert. Wenn das Modell die richtige Antwort gibt, passiert nichts. Wenn es aber die falsche gibt, also ein Hasskommentare als nicht Hass eingestuft, dann wird das Modell automatisiert angepasst. Dies passiert solange, bis das Modell fertig trainiert ist. In der Folge hat man ein fertig geschultes Modell  das man gezielt einsetzen kann. In der Theorie soll es dann in der Lage sein, auch bei neuen und bislang unbekannten Daten zwischen Beleidigungen und nicht-Beleidigungen unterscheiden zu k√∂nnen. 

[SVG src:"/static/images/ml.svg" /]
*Der Kommentar links unten (rot) wird in das Modell gef√ºttert. Wenn das Modell den Kommentar so wie Menschen bewertet, passiert nichts. Mach das Modell einen Fehler, wird es angepasst.*

###### ignore please


## Ver√§nderung √ºber die Zeit

Im n√§chsten Teil zeige ich Ihnen,, wie sich Sprache im Laufe der Zeit ver√§ndert.

[üëâ Weiter mit Teil II](/zeit/)

[hr /]

## √úbersicht

* **[Teil I: Einf√ºhrung](/)**
* [Teil II: Ver√§nderung in den Kommentaren](/zeit/)
* [Teil III: Hintergrund zu Daten & Verfahren](/hintergrund/)

[hr /]

[Thanks/]
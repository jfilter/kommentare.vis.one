[meta title:"Wie Maschinen Kommentare verstehen – Kommentare.vis.one" description:"Maschinelles Lernen wird als Lösung verkauft, um Hass aus dem Internet zu filtern. Diese Webseite erklärt wie 'die Maschinen' die Bedeutung von Wörtern erlernen." url:"https://kommentare.vis.one/" twitterHandle:"@fil_ter" shareImageUrl:"https://kommentare.vis.one/static/images/preview.png" /]


[FilterHeader
  subtitle:"Machine Learning wird als Lösung verkauft, um Hass aus dem Internet zu filtern. Diese Webseite erklärt, wie Computer die Bedeutungen von Wörtern erlernen."
  fullWidth:true
  author:"Johannes Filter"
  authorLink:"https://johannesfilter.com"
  date:"15. März 2020"
  background:"#222222"
  color:"#ffffff"
/]

[MovingTexts /]

// https://github.com/FormidableLabs/victory/blob/master/packages/victory-core/src/victory-theme/grayscale.js

[derived name:'scatter-theme' value:`{
  axis: {
    style: {
      axis: {
        fill: 'transparent',
        stroke: 'transparent'
      },
      grid: {
        stroke: 'transparent',
      },
      tickLabels: {
        stroke: 'transparent',
        fill: 'transparent'
      }
    }
  },
  scatter: {
    style: {
      data: {
        fill: "black",
        cursor: 'pointer',
        opacity: 0.8
      },
      labels: {
        fontFamily: 'lato',
        fontSize: () => Math.max(window.screen.width, window.innerWidth) < 768 ? 20 :  8,
        letterSpacing: 'normal',
        padding: 3,
        fill: 'charcoal',
        stroke: "transparent"
      }
    }
  }
}` /]

In den Kommentarspalten tobt der Hass. Um diesen einzudämmen, prüfen Zeitungsredaktionen manuell die Kommentare. Das ist personal- und zeitaufwendig. Und bei manchen Themen, ist es für die Medienhäuser kaum noch möglich, die Vielzahl an Kommentaren zu moderieren. Da wird dann die Kommentarfunktion mitunter einfach ganz abgeschaltet, um sich vor einer Flut an Hass-Kommentaren zu schützen.  

![](/static/images/news.png)
*[CC-BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/), [Christoph Hoppenbrock](https://bildbauer.de/), verändert ([Original](https://demokratielabore.de/workshops/newsbusters/))*

###### ignore please


Wie praktisch wäre es da, wenn ein Algorithmus einfach die Beleidigungen aus den Kommentaren herausfiltern könnte. Das ist grundlegend möglich mit dem sogenannten Machine Learning (Maschinelles Lernen). Mit dieser Webseite werden einzelne Verfahren des Machine Learning am Beispiel von Hasskommentaren erklärt. Der Fokus liegt auf der Verarbeitung von Sprache. Die Disziplin heißt Computerlinguistik (oder engl. Natural-Language Processing). Machine Learning wird auch bei der Verarbeitung von Bildern, z. B. der Gesichtserkennung angewandt.

[Overview1/]

## Was ist Machine Learning?

Mit dem Aufkommen der Informationstechnologie im 20. Jahrhundert wurden immer mehr Entscheidungen an Computer abgegeben. Aufgaben wurden mit Hilfe von Programmcodes gelöst. Programmier:innen formulieren einen sogenannten Algorithmus, der Hasskommentare finden soll. Das könnte etwa mit einer langen Liste funktionieren, in der alle beleidigenden Worte gesammelt sind.  Immer dann, wenn ein Wort aus der Liste in einem Kommentar auftaucht, markiert der Algorithmus den Kommentar als Hasskommentar.

Nur lässt sich dieser Ansatz leicht austricksen. Hasskommentare, die leichte Abwandlungen beinhalten, erkennt der Algorithmus nicht. Es reicht schon, wenn einzelne Buchstaben durch Zahlen ersetzt werden. Also aus "Beleidigung" wird etwa “Bele1digung” und der Kommentar wird nicht als Hasskommentar erkannt. Für den Menschen ist es einfach die Manipulation zu erkennen, für den Algorithmus ist das nicht möglich, da er sich an die vorgegebene Liste hält. Auch ist es sehr zeitaufwendig, eine solch umfassende Liste anzufertigen, da sich Sprache immer verändert und immer neue Beleidigungen kreiert werden können. Zudem kommt es auf den Kontext an, ggf. ist ein sonst beleidigendes Wort im Zusammenhang mit Satire, Ironie oder Humor anders zu verstehen. Dadurch kann es passieren, dass scherzhaft gemeinte Kommentare durch den Algorithmus als Hasskommentare gekennzeichnet werden.


Diese Probleme könnten durch die Anwendung von Machine Learning überwunden werden. Mit Machine Learning sollen Computer die Bedeutung von Wörtern erlernen, damit der Computer die Zusammenhänge verstehen kann. Es gibt zwei Arten von Machine Learning.

### 1. Überwachtes Machine Learning

Beim überwachten Machine Learning geht es darum, den Computerprogramm auf eine Problemstellung einzuspielen, damit er dann innerhalb dieses Rahmens automatisiert Antworten ausspucken kann. Beispielhafter Anwendungsfall für Bilder: Ein Programm soll erkennen, ob auf Bildern Katzen oder Hunde zu erkennen sind. In einem ersten Schritt müssen die Bilder von einem Menschen benannt werden. Die Bilder werden also als Katzen- oder Hundebilder annotiert oder gelabelt. Nur so kann der Computer dann lernen, was auf dem Bild abgebildet ist. Die richtige Antwort ist also vorgegeben. Dadurch weiß das Programm immer, ob seine eigene Antwort richtig oder falsch ist und er kann seine Parameter anhand dessen anpassen. Die Parameter eines programmes sind das Gehirn, sie werden auch als Modell bezeichnet. Im echten Betrieb, soll das Programm mit einem Modell dann ohne menschliche Hilfe Hunde von Katzen unterscheiden.

### 2. Unüberwachtes Machine Learning

Beim unüberwachten Machine Learning gibt es diese Vorgaben nicht. Ein Programm wird mit einer großen Menge an Daten gefüttert und hat keine spezifischen Anweisungen, was die Daten bedeuten sollen. Zum Beispiel: Ein Programm wird mit automatisch aus dem Internet heruntergeladenen Texten, aus digitalen Zeitungsarchiven gefüttert. Die Maschine selbst erkundet die Strukturen der Daten und soll für den Menschen daraus sinnvolle Informationen bilden.

## Klassifikation von Kommentaren

Um nun Hasskommentare automatisiert erkennen zu können, müssen das unüberwachte und das überwachte Verfahren angewandt werden. In einem ersten Schritt wird Sprache in eine für den Computer verwendbare Form umgewandelt, in Zahlen. Das geschieht durch das unüberwachte Machine Learning, bei dem der Algorithmus Milliarden von Wörtern analysiert. Aber wie läuft das genau ab? 

![](/static/images/computer.png)
*[CC-BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/), [Christoph Hoppenbrock](https://bildbauer.de/), verändert ([Original](https://demokratielabore.de))*

###### ignore please

 Es geht zunächst darum, zu verstehen, wie ein Computer Wörter interpretiert.

## Sprache, Computer und Repräsentation

Wörter sind keine Zahlen. Aber ein Computer rechnet nur mit Zahlen. Wie werden also aus Wörter Zahlen? Damit ein Computer Text analysieren kann, benötigt man für die Auswertung eine gewisse Datenmenge. Je mehr Daten der Algorithmus auswerten kann, umso besser sind die Ergebnisse aus dem Machine Learning. Zunächst müssen die Trainingsdaten mithilfe eines Tokenizers in Wörter aufgeteilt werden. In einfachen Fällen wird am Leerzeichen getrennt. Aber schon bei Satzzeichen wird es kompliziert. Zeigt zum Beispiel ein Punkt nun das Ende eines Satzes an oder die Abkürzung eines Wortes? Die Schwierigkeit wird anhand dieses Beispiels deutlich:


[SVG src:"/static/images/tokenizer.svg" /]
*Text wird durch einen Tokenizer in Wörter aufgeteilt*

###### ignore please

Jetzt haben wir Wörter. Für die Weiterverarbeitung muss der Text als eine Liste von Wörtern vorliegen. Im nächsten Abschnitt schauen wir uns an, wie genau die Bedeutung entsteht.

## Word Embeddings: Bedeutung durch Kontext

Bei dem grundlegenden Ansatz geht es um die Frage, welche Wörter treten häufig mit anderen Wörtern auf, die sogenannte Kollokation von Wörtern. Der englische Linguist [John Rupert Firth](https://en.wikipedia.org/wiki/John_Rupert_Firth) hat Mitte des 20. Jahrhunderts, einige Überlegungen dazu gemacht auf. Diese bilden noch heute das Fundament der Computerlinguistik. Zwei Zitate als Auszug:

[Aside]
> You shall know a word by the company it keeps. 
[/Aside]

> Du sollst ein Wort von seiner Umgebung kennen.

und auch

[Aside]
> The complete meaning of a word is always contextual, and no study of meaning apart from context can be taken seriously. 
[/Aside]

> Die vollständige Bedeutung eines Wortes ist immer kontextabhängig, und keine kontextunabhänige Untersuchungen über Bedeutungen kann ernst genommen werden. 

Der Kontext entscheidet also über die tatsächliche Bedeutung eines Wortes. Konkret kann man das an den folgenden Beispielen verstehen.

[Aside]
Quelle: J. R. Firth (1935) "The Technique of Semantics." und John Rupert Firth (1957) "A synopsis of linguistic theory 1930-1955."
[/Aside]

> Ich esse gerne **Fisch**. 

> Ich esse gerne **Bananen**.

> Ich esse gerne **Brot**.

Die drei Wörter kommen in ähnlichen Kontexten vor und daher weiß die Maschine, dass die beiden Wörter in einem gewissen Maße ähnlich sind. In diesem Fall, geht es um Lebensmittel. So versteht der Algorithmus, dass diese Worte zur selben Kategorie gehören. So weit so gut, doch ein Rechner arbeitet nur mit Einsen und Nullen. Um also Worte in eine Sprache des Rechners zu übersetzen, benutzt man das Word Embedding (“Wort-Einbettung”). Jedem Wort wird eine Reihe von Werten zugeschrieben. Es wird über alle Sätze hinweg gezählt, welche Wörter mit welchen anderen Wörtern verwendet werden. Als Abstand wird z. B. 2 verwendet. Alle Wörter, die maximal zwei Wörter Abstand haben, werden gezählt. Ein Beispiel:

[SVG src:"/static/images/window.svg" /]
*Jede Wortpaarung mit einem Abstand von zwei wird gezählt.*

###### ignore please

Nach dem Zählen, folgen eine Reihe weiterer Schritte, [die wir hier näher beschreiben](/) TODO. Grundsätzlich steht am Ende eine Word Embeddings links eine lange Liste an Wörtern, und auf der rechten Seite sind jedem Wort lange Zahlenkolonnen zugeordnet. Oft sind das pro Wort zwischen 300 oder 500 Zahlen werden. Anhand dieser Zahlenreihen versteht der Algorithmus die Bedeutung der Wörter. So sollen ähnliche Begriffe auch ähnliche Zahlenwerte umfassen. Da der Algorithmus nun den Worten konkrete Zahlen zugeordnet hat, kann mit diesen Werten gerechnet werden.

## Wie gut kann die Maschine Bedeutungen erlernen? Ausprobieren!

Wir haben nun ein Word Embedding trainiert und geben hier dir die Möglichkeit es auszuprobieren. Die Grundlage ist die Auswertung von über 13 Millionen Kommentaren von Zeit-Online.

## Bitte ein Wort auswählen

[Radio value:q options:`['merkel', 'mittelmeer', 'mieten', 'afd', 'migrant', 'überwachung']` /]

oder eigenes Wort eingeben:

[var name:"q" value:"merkel" /]
[TextInput value:q  /]

[var name:"chooseQ" value:`{tokens:[]}` /]
[DataLoader value:chooseQ src:`"https://ptf-vecs.app.vis.one/typeahead_videos/german_comments_2010_2019_100k?q=" + q + "&n=100"` timeout:500/]

// cut of first token if it's the same

[Radio value:q options:`q === '' ? [] : (chooseQ.tokens[0] == q ? chooseQ.tokens.slice(1) : chooseQ.tokens)` /]

[var name:"qTable" value:`{tokens:[], sims: []}` /]
[DataLoader value:qTable src:`"https://ptf-vecs.app.vis.one/sim/german_comments_2010_2019_100k?q=" + (chooseQ.tokens[0] || q) + "&n=10"` timeout:1000 /]

[br /]

Die 10 ähnlichsten Wörter (wie der Computer sie sieht) zu [Display value:`(chooseQ.tokens[0] ||  q)`/]:

[Table
    data:`qTable.tokens.map((k, i) => ({token: k, sim: qTable.sims[i]}));`
    columns:`[
        {
            Header: 'Wort',
            accessor: 'token',
        },{
            Header: 'Ähnlichkeit',
            accessor: 'sim',
            Cell: props => (props.row.sim * 100).toFixed(2) + "%",
            getProps: (state, rowInfo, column) => {
                return {
                    style: {
                        background: window.chroma.scale(['white', [42,42,123]])(rowInfo.row.sim),
                        color:  rowInfo.row.sim > 0.4 ? 'white': 'black'
                    },
                };
            },
        }
    ]`
/]

[Infokasten/]

[var name:"nearest_small" value:`{data: [], tokens:[]}` /]
[DataLoader value:nearest_small small:true src:`"https://ptf-vecs.app.vis.one/nearest/german_comments_2010_2019_100k?q=" + (chooseQ.tokens[0] || q) + "&n="` timeout:2000/]

[var name:"scrollerIndex" value:0 /]

[Scroller currentStep:scrollerIndex]
  [Graphic]
      [Chart type:`"scatter"` data:`nearest_small.data.slice(0, 1 + scrollerIndex * (nearest_small.data.length === 7 ? 2 : 3))` labels:`nearest_small.tokens.slice(0, 1 + scrollerIndex * (nearest_small.data.length === 7 ? 2 : 3))` theme:scatter-theme size:`() => Math.max(window.screen.width, window.innerWidth) < 768 ? 4: 2` /]
  [/Graphic]

  [Step]#### nur der Fokus [/Step]
  [Step]#### die nähesten Wörter[/Step]
  [Step]#### mehr Wörter[/Step]
  [Step]#### noch mehr Wörter[/Step]
[/Scroller]

[hr/]

Das ist nur ein Auschhnitt aus einem Word Embedding. In dem Word Embedding sind 100.000 Wörter enthalten, es ist nur unmöglich alle zu zeigen. Deswegen ist es besser nur Ausschnitt zu betrachten. In der Folge ein größere Ausschnitt, um mehr auf einmal zu sehen. [Oder ein anderes Wort auswählen](#bitte-ein-wort-auswählen)


[hr/]

[var name:"nearest_large" value:`{data: [], tokens:[]}` /]
[DataLoader value:nearest_large src:`"https://ptf-vecs.app.vis.one/nearest/german_comments_2010_2019_100k?q=" + (chooseQ.tokens[0] || q) + "&n=100"` timeout:2500 /]

[Graphic fullWidth:true]
  [Chart type:`"scatter"` data:`nearest_large.data` size:`() => Math.max(window.screen.width, window.innerWidth) < 768 ? 4: 2` labels:`[nearest_large.tokens[0]]` theme:scatter-theme events:`[
      {
        target: "data",
        eventHandlers: {
          onMouseOver: () => {
            return [{
              target: "labels",
              mutation: (props) => {
                return {text: nearest_large.tokens[props.index]};
              }
            }];
          },
          onMouseOut: () => {
            return [{
              target: "labels",
              mutation: (props) => {
                return {text: props.index === 0 ? nearest_large.tokens[0] : null}
              }
            }];
          }
        }
      }
    ]`
/]
[/Graphic]

[Conditional if:`nearest_small.data.length !== 7`]
  Mitte der Maus über die Punkte fahren, um die Wörter zu sehen. [Oder ein anderes Wort auswählen](#bitte-ein-wort-auswählen)
[/Conditional]

[Conditional if:`nearest_small.data.length === 7`]
  [Ein anderes Wort auswählen](#bitte-ein-wort-auswählen)
[/Conditional]

[hr /]


Für Interessierte gibt es einen Exkurs zur Klassifizierung. Ansonsten geht es weiter mit...

## Veränderung über die Zeit

Im nächsten Teil wird gezeigt, wie sich Sprache im Laufe der Zeit verändert.

[👉 Weiter mit Teil II](/zeit/)

[hr /]

## Übersicht

* *[Teil I: Einführung](/)*
* [Teil II: Veränderung in den Kommentaren](/zeit/)
* [Teil III: Hintergrund zu Daten & Verfahren](/hintergrund/)

[hr /]

[Thanks/]
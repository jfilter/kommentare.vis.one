[meta title:"Wie Maschinen Kommentare verstehen – Kommentare.vis.one" description:"Maschinelles Lernen wird als Lösung verkauft, um Hass aus dem Internet zu filtern. Diese Webseite erklärt wie 'die Maschinen' die Bedeutung von Wörtern erlernen." url:"https://kommentare.vis.one/" twitterHandle:"@fil_ter" shareImageUrl:"https://kommentare.vis.one/static/images/preview.png" /]


[FilterHeader
  subtitle:"Machine Learning wird als Lösung verkauft, um Hass aus dem Internet zu filtern. Diese Webseite erklärt, wie Computer die Bedeutungen von Wörtern erlernen."
  fullWidth:true
  author:"Johannes Filter"
  authorLink:"https://johannesfilter.com"
  date:"15. März 2020"
  background:"#222222"
  color:"#ffffff"
/]

[MovingTexts /]

// https://github.com/FormidableLabs/victory/blob/master/packages/victory-core/src/victory-theme/grayscale.js

[derived name:'scatter-theme' value:`{
  axis: {
    style: {
      axis: {
        fill: 'transparent',
        stroke: 'transparent'
      },
      grid: {
        stroke: 'transparent',
      },
      tickLabels: {
        stroke: 'transparent',
        fill: 'transparent'
      }
    }
  },
  scatter: {
    style: {
      data: {
        fill: "black",
        cursor: 'pointer',
        opacity: 0.8
      },
      labels: {
        fontFamily: 'lato',
        fontSize: () => Math.max(window.screen.width, window.innerWidth) < 768 ? 20 :  8,
        letterSpacing: 'normal',
        padding: 3,
        fill: 'charcoal',
        stroke: "transparent"
      }
    }
  }
}` /]

In den Kommentarspalten tobt der Hass. Um diesen einzudämmen, prüfen Zeitungsredaktionen manuell die Kommentare. Das ist personal- und zeitaufwendig. Und bei manchen Themen, ist es für die Medienhäuser kaum noch möglich, die Vielzahl an Kommentaren zu moderieren. Da wird dann die Kommentarfunktion mitunter einfach ganz abgeschaltet, um sich vor einer Flut an Hass-Kommentaren zu schützen.  

![](/static/images/news.png)
*[CC-BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/), [Christoph Hoppenbrock](https://bildbauer.de/), verändert ([Original](https://demokratielabore.de/workshops/newsbusters/))*

###### ignore please


Wie praktisch wäre es da, wenn ein Algorithmus einfach die Beleidigungen aus den Kommentaren herausfiltern könnte. Das ist grundlegend möglich mit dem sogenannten Machine Learning (Maschinelles Lernen). Auf dieser Webseite wird ein Verfahren des Machine Learning am Beispiel von Hasskommentaren erklärt. Der Fokus liegt auf der Verarbeitung von Sprache, die Disziplin heißt Computerlinguistik (oder engl. Natural-Language Processing). Machine Learning wird aber auch bei der Verarbeitung von Bildern, z. B. der Gesichtserkennung angewandt.

[Overview1/]

## Was ist Machine Learning?

Mit dem Aufkommen der Informationstechnologie im 20. Jahrhundert wurden immer mehr Entscheidungen an Computer abgegeben. Aufgaben wurden mithilfe von Programmcodes gelöst. Ein traditioneller Ansatz: Programmier:innen formulieren einen Algorithmus, der Hasskommentare finden soll. Das könnte etwa mit einer langen Liste aller beleidigenden Wörter funktionieren. Immer dann, wenn ein Wort aus der Liste in einem Kommentar auftaucht, markiert der Algorithmus den Kommentar als Hasskommentar.

Nur lässt sich dieser Ansatz leicht austricksen. Hasskommentare, die leichte Abwandlungen beinhalten, erkennt der Algorithmus nicht. Es reicht schon, wenn einzelne Buchstaben durch Zahlen ersetzt werden. Also aus "Beleidigung" wird etwa “Bele1digung” (z. B. "Dummk0pf") und der Kommentar wird nicht als Hasskommentar erkannt. Für den Menschen ist es einfach die Manipulation zu erkennen, für den Algorithmus ist das nicht möglich, da er sich an die vorgegebene Liste hält. Auch ist es sehr zeitaufwendig, eine solch umfassende Liste anzufertigen, da sich Sprache immer verändert und immer neue Beleidigungen kreiert werden können. Zudem kommt es auf den Kontext an, ein einzelnes Wort ist eventuell nur im Zusammenhang mit anderen Wörtern problematisch.

Diese Probleme könnten durch die Anwendung von Machine Learning überwunden werden. Mit Machine Learning sollen Computer die Bedeutung von Wörtern und ganzen Sätzen erlernen, damit der Computer die Zusammenhänge verstehen kann. Es gibt zwei Arten von Machine Learning:

### 1. Überwachtes Machine Learning

Beim überwachten Machine Learning geht es darum, den Computerprogramm auf eine Problemstellung einzuspielen, damit er dann innerhalb dieses Rahmens automatisiert Antworten ausspucken kann. Beispielhafter Anwendungsfall für Bilder: Ein Programm soll erkennen, ob auf Bildern Katzen oder Hunde zu erkennen sind. In einem ersten Schritt müssen die Bilder von einem Menschen benannt werden. Die Bilder werden als Katzen- oder Hundebilder annotiert oder gelabelt. Nur so kann der Computer daraufhin lernen, was auf dem Bild abgebildet ist. Die richtige Antwort ist zunächst vorgegeben. Dadurch weiß das Programm immer, ob seine eigene Antwort richtig oder falsch ist und er kann seine Parameter anhand dessen anpassen ("trainiert"). Die Parameter eines Programmes sind das Gehirn, sie werden auch als Modell bezeichnet. Im echten Betrieb, soll das Programm mit einem Modell ohne menschliche Hilfe Hunde von Katzen unterscheiden.

### 2. Unüberwachtes Machine Learning

Beim unüberwachten Machine Learning gibt es diese Vorgaben nicht. Ein Programm wird mit einer großen Menge an Daten gefüttert und hat keine spezifischen Anweisungen, was die Daten bedeuten sollen. Zum Beispiel: Ein Programm wird mit automatisch aus dem Internet heruntergeladenen Texten aus digitalen Zeitungsarchiven gefüttert. Die Maschine selbst erkundet die Strukturen der Daten und soll für den Menschen daraus sinnvolle Informationen bilden.

## Klassifikation von Kommentaren

Um nun Hasskommentare automatisiert erkennen zu können, müssen Verfahren aus dem unüberwachte und dem überwachte Machine Learning angewandt werden. In einem ersten Schritt wird Sprache in eine für den Computer verwendbare Form umgewandelt, in Zahlen. Das geschieht durch das unüberwachte Machine Learning, bei dem der Algorithmus Milliarden von Wörtern analysiert. Aber wie läuft das genau ab? 

![](/static/images/computer.png)
*[CC-BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/), [Christoph Hoppenbrock](https://bildbauer.de/), verändert ([Original](https://demokratielabore.de))*

###### ignore please

 Es geht zunächst darum, zu verstehen, wie ein Computer Wörter interpretiert.

## Sprache, Computer und Repräsentation

Wörter sind keine Zahlen, aber ein Computer rechnet nur mit Zahlen. Wie werden also aus Wörter Zahlen? Damit ein Computer Text analysieren kann, benötigt man für die Auswertung eine gewisse Datenmenge. Je mehr Daten der Algorithmus auswerten kann, umso besser sind die Ergebnisse aus dem Machine Learning. Zunächst wird eine große Mengen an Fließtext gebraucht, wie z. B. tausende Nachrichtenartikel. Dann müssen die Trainingsdaten mithilfe eines Programms, eines Tokenizers, in Wörter aufgeteilt werden. In einfachen Fällen wird am Leerzeichen getrennt. Aber schon bei Satzzeichen wird es kompliziert. Zeigt zum Beispiel ein Punkt nun das Ende eines Satzes an oder die Abkürzung eines Wortes? Die Schwierigkeit wird anhand dieses Beispiels deutlich:


[SVG src:"/static/images/tokenizer.svg" /]
*Text wird durch einen Tokenizer in Wörter aufgeteilt*

###### ignore please

Durch den Tokenizer sind die Texte in eine Liste von Wörtern zerlegt. Im nächsten Abschnitt wird erklärt, wie genau die Bedeutung entsteht.

## Word Embeddings: Bedeutung durch Kontext

Bei dem grundlegenden Ansatz geht es um die Frage, welche Wörter treten häufig mit anderen Wörtern auf, die sogenannte Kollokation von Wörtern. Der englische Linguist [John Rupert Firth](https://de.wikipedia.org/wiki/John_Rupert_Firth) hat Mitte des 20. Jahrhunderts, einige Überlegungen dazu gemacht auf. Diese bilden noch heute das Fundament der Computerlinguistik. Zwei Zitate als Auszug:

[Aside]
> You shall know a word by the company it keeps. 
[/Aside]

> Du sollst ein Wort von seiner Umgebung kennen.

und auch

[Aside]
> The complete meaning of a word is always contextual, and no study of meaning apart from context can be taken seriously. 
[/Aside]

> Die vollständige Bedeutung eines Wortes ist immer kontextabhängig, und keine kontextunabhänige Untersuchungen über Bedeutungen kann ernst genommen werden. 

[Aside]

Quelle: John Rupert Firth "The Technique of Semantics." (1935) "A synopsis of linguistic theory 1930-1955." (1957)

[/Aside]

Durch die Analyse von Kollokation von Wörter kann automatisiert die Bedeutung von Wörtern abgeleitet werden. Anbei ein Beispiel.


> Ich esse gerne **Fisch**. 

> Ich esse gerne **Bananen**.

> Ich esse gerne **Brot**.

Die drei Wörter (Fisch, Bananen, Brot) kommen in ähnlichen Kontexten vor und daher weiß die Maschine, dass die beiden Wörter in einem gewissen Maße ähnlich sind. In diesem Fall, geht es um Lebensmittel. So versteht der Algorithmus, dass diese Wörter zur selben Kategorie gehören.

Es wird über alle Sätze hinweg gezählt, welche Wörter mit welchen anderen Wörtern verwendet werden. Als Abstand wird z. B. 2 verwendet: Alle Wörter, die maximal zwei Wörter Abstand haben, werden gezählt. Ein Beispiel:

[SVG src:"/static/images/window.svg" /]
*Jede Wortpaarung mit einem Abstand von zwei wird gezählt*

###### ignore please

Nach dem Zählen folgen eine [Reihe weiterer mathematischer Schritte](/hintergrund#wie-genau-wurden-die-word-embeddings-erstellt?).
Am Ende entsteht ein sogenannte Word Embedding (“Wort-Einbettung”), um Worte in eine Sprache des Rechners (Zahlen) zu übersetzen.
Grundsätzlich ordnet ein Word Embeddings jedem Wort eine Reihe von Werten zugeschrieben. Oft sind das lange Zahlenkolonnen zwischen 300 oder 500 Zahlen  pro Wort.
Anhand dieser Zahlenreihen versteht der Algorithmus die Bedeutung der Wörter.
So sollen ähnliche Begriffe auch ähnliche Zahlenwerte umfassen.
Da der Algorithmus nun den Wörten konkrete Zahlen zugeordnet hat, kann mit diesen Werten gerechnet werden.

## Wie gut kann die Maschine Bedeutungen erlernen? Ausprobieren!

Ich habe ein Word Embedding trainiert und gebe hier dir die Möglichkeit es auszuprobieren. Die Grundlage bilden über 13 Millionen deutsche Online-Kommentaren von 2010 bis 2019. Es gibt keine reine Zahlendarstellung weil dies nicht anschaulich ist. Jedoch werden zu einem ausgewählen Wort ähnliche Begriffe angezeigt. *Ähnlich* bedeutet hier, dass der Computer (durch das Word Embedding) das so sieht.

## Bitte ein Wort auswählen

[Radio value:q options:`['auto', 'berlin', 'merkel', 'mittelmeer', 'mieten', 'afd', 'migrant', 'überwachung']` /]

oder eigenes Wort eingeben:

[var name:"q" value:"auto" /]
[TextInput value:q  /]

[var name:"chooseQ" value:`{tokens:[]}` /]
[DataLoader value:chooseQ src:`"https://kommentare.vis.one/vectors/typeahead_videos/german_comments_2010_2019_100k?q=" + q + "&n=100"` timeout:300/]

// cut of first token if it's the same

[Radio value:q options:`q === '' ? [] : (chooseQ.tokens[0] == q ? chooseQ.tokens.slice(1) : chooseQ.tokens)` /]

[var name:"qTable" value:`{tokens:[], sims: []}` /]
[DataLoader value:qTable src:`"https://kommentare.vis.one/vectors/sim/german_comments_2010_2019_100k?q=" + (chooseQ.tokens[0] || q) + "&n=10"` timeout:600 /]

[br /]

Die 10 ähnlichsten Wörter zu [Display value:`(chooseQ.tokens[0] ||  q)`/] (so wie es der Computer sieht):

[Table
    data:`qTable.tokens.map((k, i) => ({token: k, sim: qTable.sims[i]}));`
    columns:`[
        {
            Header: 'Wort',
            accessor: 'token',
        },{
            Header: 'Ähnlichkeit',
            accessor: 'sim',
            Cell: props => (props.row.sim * 100).toFixed(2) + " %",
            getProps: (state, rowInfo, column) => {
                return {
                    style: {
                        background: window.chroma.scale(['white', [42,42,123]])(rowInfo.row.sim),
                        color:  rowInfo.row.sim > 0.4 ? 'white': 'black'
                    },
                };
            },
        }
    ]`
/]

[Infokasten/]

[var name:"nearest_small" value:`{data: [], tokens:[]}` /]
[DataLoader value:nearest_small small:true src:`"https://kommentare.vis.one/vectors/nearest/german_comments_2010_2019_100k?q=" + (chooseQ.tokens[0] || q) + "&n="` timeout:2000/]

[var name:"scrollerIndex" value:0 /]

[Scroller currentStep:scrollerIndex]
  [Graphic]
      [Chart type:`"scatter"` data:`nearest_small.data.slice(0, 1 + scrollerIndex * (nearest_small.data.length === 7 ? 2 : 3))` labels:`nearest_small.tokens.slice(0, 1 + scrollerIndex * (nearest_small.data.length === 7 ? 2 : 3))` theme:scatter-theme size:`() => Math.max(window.screen.width, window.innerWidth) < 768 ? 4: 2` /]
  [/Graphic]

  [Step]#### zu diesem Wort zeigen wir ähnliche Begriffe [/Step]
  [Step]#### das sind die nähesten Wörter[/Step]
  [Step]#### mehr Wörter[/Step]
  [Step]#### noch mehr Wörter [/Step]
[/Scroller]

[hr/]

Das ist nur ein kleiner Auschhnitt aus einem Word Embedding. In dem Word Embedding sind 100.000 Wörter enthalten, es ist nur unmöglich alle zu zeigen. In der Folge ein größerer Ausschnitt, um mehr auf einmal zu sehen.

[Oder wähle ein anderes Wort aus](#bitte-ein-wort-auswählen)


[hr/]

[var name:"nearest_large" value:`{data: [], tokens:[]}` /]
[DataLoader value:nearest_large src:`"https://kommentare.vis.one/vectors/nearest/german_comments_2010_2019_100k?q=" + (chooseQ.tokens[0] || q) + "&n=100"` timeout:2500 /]

[Graphic fullWidth:true]
  [Chart type:`"scatter"` data:`nearest_large.data` size:`() => Math.max(window.screen.width, window.innerWidth) < 768 ? 4: 2` labels:`[nearest_large.tokens[0]]` theme:scatter-theme events:`[
      {
        target: "data",
        eventHandlers: {
          onMouseOver: () => {
            return [{
              target: "labels",
              mutation: (props) => {
                return {text: nearest_large.tokens[props.index]};
              }
            }];
          },
          onMouseOut: () => {
            return [{
              target: "labels",
              mutation: (props) => {
                return {text: props.index === 0 ? nearest_large.tokens[0] : null}
              }
            }];
          }
        }
      }
    ]`
/]
[/Graphic]

[Conditional if:`nearest_small.data.length !== 7`]
  Mitte der Maus über die Punkte fahren, um die Wörter zu sehen. [Oder ein anderes Wort auswählen](#bitte-ein-wort-auswählen)
[/Conditional]

[Conditional if:`nearest_small.data.length === 7`]
  Auf mobilen Geräten erfolgt nur eine reduzierte Darstellung. [Ein anderes Wort auswählen](#bitte-ein-wort-auswählen)
[/Conditional]

[hr /]


Das war es für den ersten Teil. Für Interessierte gibt es einen weitern [Exkurs zur Klassifizierung](/hintergrund#wie-genau-werden-mithilfe-von-word-embeddings-kommentare-klassifiziert?). Im nächsten Teil wird gezeigt, wie sich die Sprache in den Kommentaren im Laufe der Zeit veränderte.

[👉 Weiter zu Teil II](/zeit/)

[hr /]

## Übersicht

* *[Teil I: Einführung](/)*
* [Teil II: Veränderung in den Kommentaren](/zeit/)
* [Teil III: Hintergrund zu Daten & Verfahren](/hintergrund/)

[hr /]

[Thanks/]